<div align="center">

## ğŸ“– Language / è¯­è¨€é€‰æ‹©

[![English](https://img.shields.io/badge/ğŸ‡ºğŸ‡¸_English-Click_Here-0078D4?style=for-the-badge)](#english)
[![ç®€ä½“ä¸­æ–‡](https://img.shields.io/badge/ğŸ‡¨ğŸ‡³_ç®€ä½“ä¸­æ–‡-ç‚¹å‡»è¿™é‡Œ-FF0000?style=for-the-badge)](#ä¸­æ–‡)

</div>

---

<a name="english"></a>

# Industrial Digital Twin by Transformer

**[English](#english)** | **[ä¸­æ–‡](#ä¸­æ–‡)**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **An innovative Transformer-based framework for industrial digital twin modeling using sequential sensor outputs from complex systems with advanced residual boost training.**

This project introduces Transformer architectures and residual boost training methodology specifically designed for predicting sensor outputs in industrial digital twin applications. Unlike traditional approaches, our models leverage the **sequential nature of multi-sensor systems** in complex industrial environments to achieve improved prediction accuracy through multi-stage refinement.

---

**If you find this project helpful, please consider giving it a â­ star! Your support helps others discover this work and motivates continued development.**

---

## ğŸŒŸ Key Innovation

**Sequential Sensor Prediction using Transformers**: This framework applies Transformer architecture to the problem of predicting sequential sensor outputs in industrial digital twins. The model treats multiple sensors as a sequence, capturing both spatial relationships between sensors and temporal dependencies in their measurements.

### Why This Matters

In complex industrial systems (manufacturing plants, chemical processes, power generation, etc.), sensors don't operate in isolation. Their outputs are:
- **Spatially correlated**: Physical proximity and process flow create dependencies
- **Temporally dependent**: Historical measurements influence current and future readings
- **Hierarchically structured**: Some sensors measure boundary conditions while others measure internal states

Traditional machine learning approaches treat sensors independently or use simple time-series models. Our Transformer-based approach **captures the full complexity of sensor interrelationships**.

## ğŸš€ Features

### Model Architecture

#### **StaticSensorTransformer (SST)**
- **Purpose**: Maps boundary condition sensors to target sensor predictions
- **Architecture**: Sensor sequence Transformer with learned positional encodings
- **Innovation**: Treats fixed sensor arrays as sequences (replacing NLP token sequences)
- **Use Case**: Industrial systems with complex sensor inter-dependencies
- **Advantages**:
  - Captures spatial sensor relationships through attention mechanism
  - Fast training and inference
  - Learns physical causality between sensors
  - Excellent for industrial digital twin applications

### ğŸ†• Enhanced Residual Boost Training System (v1.0)

#### **Stage2 Boost Training** ğŸš€
- Train secondary models on residuals from SST predictions
- Further refine predictions for improved accuracy
- Configurable architecture and training parameters
- Automatic model saving and versioning

#### **Intelligent Delta RÂ² Threshold Selection** ğŸ¯
- Calculate Delta RÂ² (RÂ²_ensemble - RÂ²_stage1) for each signal
- Selectively apply Stage2 corrections based on Delta RÂ² threshold
- Generate ensemble models combining SST + Stage2
- Optimized performance/efficiency balance
- Only use Stage2 for signals where it provides significant improvement

#### **Comprehensive Inference Comparison** ğŸ“Š
- Compare ensemble model vs. pure SST model
- Visualize performance improvements for all output signals
- Detailed per-signal metrics analysis (MAE, RMSE, RÂ²)
- CSV export with predictions and RÂ² scores
- Interactive index range selection

#### **All-Signal Visualization** ğŸ“ˆ
- Individual prediction vs actual comparison for every output signal
- Dynamic layout adapting to number of signals
- RÂ² scores displayed for each signal
- Easy identification of model improvements

### âš¡ Lightweight & Edge-Ready Architecture

#### **Ultra-Lightweight Transformer Design**
Despite being Transformer-based, our models are designed as **ultra-lightweight variants** that maintain exceptional performance while minimizing computational requirements:

- **Edge Device Optimized**: Train and deploy on resource-constrained hardware
- **Fast Inference**: Real-time predictions with minimal latency
- **Low Memory Footprint**: Efficient model architecture for embedded systems
- **Rapid Training**: Quick model convergence even on limited compute

#### **Digital Twin Anything: Universal Edge Deployment** ğŸŒ

Our design philosophy enables **personalized digital twins for individual assets**:

- **Per-Vehicle Digital Twins**: Dedicated models for each car or vehicle
- **Per-Engine Monitoring**: Individual engine-specific predictive models
- **Device-Level Customization**: Any system with sufficient testbench sensor data can have its own lightweight digital twin
- **Automated Edge Pipeline**: Complete training and inference pipeline deployable on edge devices

**Vision**: Create an automated, lightweight digital twin for **anything** - from individual machines to entire production lines, all running on edge hardware with continuous learning capabilities.

#### **Future Potential: Simulation Model Surrogate** ğŸ”¬

**Envisioned application for computational efficiency**:

The lightweight nature of our Transformer architecture opens an exciting future possibility:
- Treat each simulation mesh region as a virtual "sensor"
- Potentially use lightweight Transformers to learn complex simulation behaviors
- **Could reverse-engineer expensive simulations** with orders of magnitude less computational cost
- May maintain high accuracy while enabling real-time simulation surrogate models
- Promising for CFD, FEA, and other computationally intensive simulations

This approach could unlock new possibilities:
- Real-time simulation during design iterations
- Democratizing access to high-fidelity simulations
- Embedding complex physics models in edge devices
- Accelerating digital twin development cycles

*Note: This represents a theoretical framework and future research direction that has not yet been fully validated in production environments.*

### Additional Features

- âœ… **Modular Design**: Easy to extend and customize
- âœ… **Comprehensive Training Pipeline**: Built-in data preprocessing, training, and evaluation
- âœ… **Interactive Gradio Interface**: User-friendly web interface for all training stages
- âœ… **Jupyter Notebooks**: Complete tutorials and examples
- âœ… **Production Ready**: Exportable models for deployment
- âœ… **Extensive Documentation**: Clear API documentation and usage examples
- âœ… **Automated Model Management**: Intelligent model saving and loading with configurations

## ğŸ“Š Use Cases

This framework is ideal for:

- **Manufacturing Digital Twins**: Predict equipment states from sensor arrays
- **Chemical Process Monitoring**: Model complex sensor interactions in reactors
- **Power Plant Optimization**: Forecast turbine and generator conditions
- **HVAC Systems**: Predict temperature and pressure distributions
- **Predictive Maintenance**: Early detection of anomalies from sensor patterns
- **Quality Control**: Predict product quality from process sensors

## ğŸ—ï¸ Architecture Overview

### ğŸ”‘ Core Innovation: Sensors as Sequence Elements

**Traditional NLP Transformers vs. SST (Our Innovation)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NLP Transformer (Traditional)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  [The, cat, sits, on, the, mat]  â† Words as tokens      â”‚
â”‚ Embed:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ,   Eâ‚„,  Eâ‚…,  Eâ‚†]  â† Word embeddings      â”‚
â”‚ Pos:    [Pâ‚,  Pâ‚‚,  Pâ‚ƒ,   Pâ‚„,  Pâ‚…,  Pâ‚†]  â† Temporal order       â”‚
â”‚ Attn:   Semantic relationships between words                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â¬‡ï¸  INNOVATION  â¬‡ï¸

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SST - Sensor Sequence Transformer (Ours)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input:  [Sâ‚,  Sâ‚‚,  Sâ‚ƒ, ..., Sâ‚™]  â† Fixed sensor array          â”‚
â”‚         (Temp, Pressure, Flow, ...)                             â”‚
â”‚ Embed:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ, ..., Eâ‚™]  â† Sensor value embeddings     â”‚
â”‚ Pos:    [Pâ‚,  Pâ‚‚,  Pâ‚ƒ, ..., Pâ‚™]  â† SPATIAL locations           â”‚
â”‚ Attn:   Physical causality & sensor inter-dependencies          â”‚
â”‚                                                                  â”‚
â”‚ Key Differences:                                                 â”‚
â”‚ â€¢ Fixed sequence length (N sensors predetermined)               â”‚
â”‚ â€¢ Position = Sensor location, NOT temporal order                â”‚
â”‚ â€¢ Attention learns cross-sensor physical relationships          â”‚
â”‚ â€¢ Domain-specific for industrial systems                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ SST Architecture Deep Dive

```
Physical Sensor Array: [Sensorâ‚, Sensorâ‚‚, ..., Sensorâ‚™]
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Sensor Embedding Layer                        â”‚
â”‚  â€¢ Projects each scalar sensor reading â†’ d_model dimensions     â”‚
â”‚  â€¢ Each sensor gets its own embedding transformation            â”‚
â”‚  â€¢ Input: (batch, N_sensors) â†’ Output: (batch, N_sensors, d_model)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Learnable Position Encoding                        â”‚
â”‚  â€¢ Unlike NLP: Encodes SPATIAL sensor positions                 â”‚
â”‚  â€¢ Learns sensor location importance (e.g., inlet vs outlet)    â”‚
â”‚  â€¢ Shape: (N_sensors, d_model) - one per sensor                â”‚
â”‚  â€¢ Added to embeddings: Embed + PosEncode                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Multi-Head Self-Attention Mechanism                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Head 1: Learns temperature-pressure relationships        â”‚  â”‚
â”‚  â”‚ Head 2: Learns flow-velocity correlations               â”‚  â”‚
â”‚  â”‚ Head 3: Learns spatial proximity effects                â”‚  â”‚
â”‚  â”‚ ...                                                      â”‚  â”‚
â”‚  â”‚ Head N: Learns system-wide dependencies                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â€¢ Captures complex, non-linear sensor interactions             â”‚
â”‚  â€¢ Attention weights reveal sensor importance                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Transformer Encoder Stack                      â”‚
â”‚  Layer 1: Attention + FFN + Residual                            â”‚
â”‚  Layer 2: Attention + FFN + Residual                            â”‚
â”‚  ...                                                             â”‚
â”‚  Layer L: Attention + FFN + Residual                            â”‚
â”‚  â€¢ Each layer refines sensor relationship understanding         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Global Pooling (Sequence Aggregation)               â”‚
â”‚  â€¢ Adaptive average pooling over sensor sequence                â”‚
â”‚  â€¢ Aggregates information from all sensors                      â”‚
â”‚  â€¢ Output: (batch, d_model) - fixed-size representation        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Output Projection Layer                       â”‚
â”‚  â€¢ Projects aggregated representation â†’ target sensor values    â”‚
â”‚  â€¢ Linear transformation: d_model â†’ N_target_sensors           â”‚
â”‚  â€¢ Final predictions: (batch, N_target_sensors)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              Target Sensor Predictions
```

### ğŸ“Š Stage2 Residual Boost System

Built on top of SST, the Stage2 system further refines predictions:

```
Step 1: Base SST Model
   Boundary Sensors â†’ [SST] â†’ Predictions + Residuals

Step 2: Stage2 Residual Model
   Boundary Sensors â†’ [SSTâ‚‚] â†’ Residual Corrections

Step 3: Intelligent Delta RÂ² Selection
   For each target signal:
     Delta RÂ² = RÂ²_ensemble - RÂ²_stage1
     if Delta RÂ² > threshold: Apply Stage2 correction
     else: Use base SST prediction

Step 4: Final Ensemble Model
   Predictions = Stage1 predictions + selective Stage2 corrections
```

## ğŸ”§ Installation

### Quick Start with Google Colab

```bash
# Clone the repository
!git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
%cd Industrial-digital-twin-by-transformer

# Install dependencies
!pip install -r requirements.txt
```

### Local Installation

```bash
# Clone the repository
git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“š Quick Start

### 1. Prepare Your Data

Place your CSV sensor data file in the `data/raw/` folder. Your CSV should have:
- Each row represents a timestep
- Each column represents a sensor measurement
- (Optional) First column can be a timestamp

Example CSV structure:
```csv
timestamp,sensor_1,sensor_2,sensor_3,...,sensor_n
2025-01-01 00:00:00,23.5,101.3,45.2,...,78.9
2025-01-01 00:00:01,23.6,101.4,45.1,...,79.0
...
```

### 2. Train Stage1 Model Using Jupyter Notebook (Basic Training)

This section demonstrates **basic Stage1 (SST) model training** for learning sensor prediction fundamentals.

**Note**: The notebook provides a foundation for understanding the SST architecture and basic training process. For the complete Stage2 Boost training and ensemble model generation, please use the enhanced Gradio interface (Section 3).

**Available Notebooks**:
- `notebooks/Train and run model with demo data and your own data with gradio interface.ipynb` - Quick start tutorial for beginners
- `notebooks/transformer_boost_Leap_final.ipynb` - Advanced example: Complete Stage1 + Stage2 training on LEAP dataset (Author's testing file, comments in Chinese)

**Basic Training Example** (for your own data):

```python
from models.static_transformer import StaticSensorTransformer
from src.data_loader import SensorDataLoader
from src.trainer import ModelTrainer

# Load data
data_loader = SensorDataLoader(data_path='data/raw/your_data.csv')

# Configure signals
boundary_signals = ['sensor_1', 'sensor_2', 'sensor_3']  # Inputs
target_signals = ['sensor_4', 'sensor_5']  # Outputs to predict

# Prepare data
data_splits = data_loader.prepare_data(boundary_signals, target_signals)

# Create and train Stage1 SST model
model = StaticSensorTransformer(
    num_boundary_sensors=len(boundary_signals),
    num_target_sensors=len(target_signals)
)

trainer = ModelTrainer(model, device='cuda')
history = trainer.train(train_loader, val_loader)

# Save trained model
torch.save(model.state_dict(), 'saved_models/my_sst_model.pth')
```

**What you'll learn in Stage1**:
- Loading and preprocessing sensor data
- Configuring boundary and target sensors
- Training the Static Sensor Transformer (SST)
- Basic model evaluation and prediction

**For complete functionality** (Stage2 Boost + Ensemble Models), proceed to Section 3.

### 3. Use Enhanced Gradio Interface (Complete Stage1 + Stage2 Training)

**Gradio UI Demo Video**: Coming soon

#### **Getting Started with Jupyter Notebook Tutorial**

For a step-by-step guide, see:
- `notebooks/Train and run model with demo data and your own data with gradio interface.ipynb`

This notebook demonstrates:
- Downloading demo data from Kaggle (power-gen-machine dataset)
- Setting up the Gradio interface
- Training with demo data or your own custom data

Simply follow the notebook steps to get started with the complete workflow.

#### **Complete Workflow**

The enhanced interface provides the **complete end-to-end workflow**:
- ğŸ“Š **Tab 1: Data Loading** - Refresh and select demo data (`data.csv`) or upload your own CSV
- ğŸ¯ **Tab 2: Signal Configuration & Stage1 Training** - Refresh, load signal configuration, select parameters, and train base SST models
- ğŸ”¬ **Tab 3: Residual Extraction** - Extract and analyze prediction errors from Stage1 models
- ğŸš€ **Tab 4: Stage2 Boost Training** - Train secondary models on residuals for error correction
- ğŸ¯ **Tab 5: Ensemble Model Generation** - Intelligent Delta RÂ² threshold-based model combination
- ğŸ“Š **Tab 6: Inference Comparison** - Compare Stage1 SST vs. ensemble model performance with visualizations
- ğŸ’¾ **Tab 7: Export** - Automatic model saving with complete configurations

**This is the recommended way to experience the full capabilities of the framework**, including:
- Automated multi-stage training pipeline using demo data
- Intelligent signal-wise Stage2 selection
- Comprehensive performance metrics and visualizations
- Production-ready ensemble model generation

**Using Your Own Data**:
Simply place your CSV file in the `data/` folder, refresh in Tab 1, and select your file. Ensure your CSV follows the same format as the demo data (timesteps as rows, sensors as columns). Then configure your own input/output signals in Tab 2.

**Quick Start Guide**: See `docs/QUICKSTART.md` for a 5-minute tutorial

## ğŸ“– Documentation

### Project Structure

```
Industrial-digital-twin-by-transformer/
â”œâ”€â”€ models/                      # Model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ static_transformer.py    # SST (StaticSensorTransformer)
â”‚   â”œâ”€â”€ utils.py                # Utility functions
â”‚   â””â”€â”€ saved/                  # Saved model checkpoints
â”œâ”€â”€ saved_models/               # Trained models with configs
â”‚   â”œâ”€â”€ StaticSensorTransformer_*.pth   # SST models
â”‚   â”œâ”€â”€ stage2_boost/           # Stage2 residual models
â”‚   â”œâ”€â”€ ensemble/               # Ensemble model configs
â”‚   â””â”€â”€ tft_models/            # TFT models (if used)
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py         # Data loading and preprocessing
â”‚   â”œâ”€â”€ trainer.py             # Training pipeline
â”‚   â””â”€â”€ inference.py           # Inference engine
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ ENHANCED_VERSION_README.md  # Enhanced features guide
â”‚   â”œâ”€â”€ UPDATE_NOTES.md        # Detailed update notes
â”‚   â”œâ”€â”€ QUICKSTART.md          # 5-minute quick start
â”‚   â””â”€â”€ FILE_MANIFEST.md       # File structure guide
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â”œâ”€â”€ transformer_boost_Leap_final.ipynb  # Author's testing file on LEAP dataset (comments in Chinese)
â”‚   â””â”€â”€ Train and run model with demo data and your own data with gradio interface.ipynb  # Quick start tutorial
â”œâ”€â”€ data/                      # Data folder
â”‚   â”œâ”€â”€ raw/                   # Place your CSV files here
â”‚   â””â”€â”€ residuals_*.csv       # Extracted residuals
â”œâ”€â”€ examples/                  # Example scripts
â”‚   â””â”€â”€ quick_start.py        # Quick start example
â”œâ”€â”€ configs/                   # Configuration files
â”œâ”€â”€ archive/                   # Archived old files
â”‚   â”œâ”€â”€ gradio_app.py         # Old simple interface
â”‚   â”œâ”€â”€ gradio_full_interface.py  # Old full interface
â”‚   â””â”€â”€ hybrid_transformer.py  # Deprecated HST model
â”œâ”€â”€ gradio_sensor_transformer_app.py # ğŸ†• Enhanced Gradio application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package setup
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                # This file
```

### Model APIs

#### StaticSensorTransformer (SST)

```python
from models.static_transformer import StaticSensorTransformer

model = StaticSensorTransformer(
    num_boundary_sensors=10,    # Number of input sensors
    num_target_sensors=5,       # Number of output sensors
    d_model=128,                # Model dimension
    nhead=8,                    # Number of attention heads
    num_layers=3,               # Number of transformer layers
    dropout=0.1                 # Dropout rate
)

# Forward pass
predictions = model(boundary_conditions)  # Shape: (batch_size, num_target_sensors)
```

#### Stage2 Residual Boost Training

```python
# Step 1: Train base SST model
base_model = StaticSensorTransformer(...)
# ... train base model ...

# Step 2: Extract residuals
residuals = true_values - base_model_predictions

# Step 3: Train Stage2 model on residuals
stage2_model = StaticSensorTransformer(...)
# ... train stage2 on residuals ...

# Step 4: Generate ensemble with intelligent Delta RÂ² selection
for signal_idx in range(num_signals):
    r2_base = calculate_r2(true_values[:, signal_idx], base_predictions[:, signal_idx])
    r2_ensemble = calculate_r2(true_values[:, signal_idx], base_pred[:, signal_idx] + stage2_pred[:, signal_idx])
    delta_r2 = r2_ensemble - r2_base

    if delta_r2 > threshold:  # e.g., threshold=0.05 (5% improvement)
        # Use Stage2 correction (significant improvement)
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx] + stage2_pred[:, signal_idx]
    else:
        # Keep base prediction (no significant improvement)
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx]
```

**Note**: The enhanced Gradio interface (`gradio_sensor_transformer_app.py`) automates this entire workflow.

## ğŸ¯ Performance

### Benchmark Results

#### ğŸ­ Industrial Rotating Machinery Case Study

**Dataset**: [Power Generation Machine Sensor Data](https://www.kaggle.com/datasets/tianffan/power-gen-machine)

**Application Domain**: Real-world advanced rotating machinery for power generation
- Multi-sensor system monitoring for complex industrial equipment
- High-frequency operational data from production environment
- Representative of industrial digital twin applications

**Dataset Characteristics**:
- **Source**: Real industrial equipment sensor array
- **Complexity**: Multi-sensor interdependencies in high-performance rotating systems
- **Scale**: Full operational sensor suite covering critical parameters
- **Quality**: Production-grade sensor measurements

**Performance Results** (Test Set):

| Metric | Stage1 (SST) | Stage1+Stage2 Ensemble | Improvement |
|--------|--------------|------------------------|-------------|
| **RÂ²** | 0.8101 | **0.9014** | +11.3% |
| **MAE** | 1.56 | **1.24** | -20.2% |
| **RMSE** | 3.89 | **3.57** | -8.3% |

**Configuration**:
- **Dataset**: 89 target signals, 217K samples
- **Stage1**: 50 epochs, default hyperparameters
- **Stage2**: Selective boost on 36/89 signals (Delta RÂ² threshold: 0.03)
- **Hardware**: Single NVIDIA A100 GPU
- **Training**: No data augmentation, no special tuning

**Training Recommendations** (Based on Practical Experience):

The above results were achieved with default hyperparameters. However, **better performance can typically be obtained** with the following parameter tuning strategy:
- ğŸ“‰ **Lower learning rate**: Smaller learning rates (e.g., 0.00003 vs. default 0.0001) often lead to better convergence
- â±ï¸ **Higher scheduler patience**: Increased learning rate scheduler patience (e.g., 8 vs. default 3) allows more stable training
- ğŸ“Š **Higher decay factor**: Higher learning rate decay factors reduce aggressive learning rate reductions
- ğŸ”„ **More epochs**: Training for more epochs with the above settings generally improves final performance

These adjustments help achieve smoother convergence and better generalization, especially for complex industrial sensor systems.

**Stage2 Intelligent Selection**:
- **36 signals** selected for Stage2 correction (significant improvement observed)
- **53 signals** kept Stage1-only predictions (already performing well)
- Adaptive strategy balances performance gains with computational efficiency

**Example Signal Improvements** (Stage1 â†’ Ensemble):
- Vibration sensors: RÂ² -0.13 â†’ 0.26, -0.55 â†’ 0.47 (challenging signals)
- Temperature sensors: RÂ² 0.35 â†’ 0.59, 0.68 â†’ 0.93 (moderate improvements)
- Pressure sensors: RÂ² 0.08 â†’ 0.47, 0.42 â†’ 0.63 (significant gains)

<details>
<summary><b>ğŸ“Š Click to View Full Results Visualization (All Signals Prediction Performance)</b></summary>

<br>

The following image shows the prediction performance of all 89 target signals on the test set after Stage1 + Stage2 Boost:

![All Signals Prediction Results Demo](saved_models/result_demo.webp)

**Figure Description**:
- Blue line: Ground Truth
- Orange line: Model Prediction
- Each subplot represents the prediction performance of one sensor signal
- Most signals show predictions closely matching ground truth values

</details>

**Practical Insights**:
- âœ… **Strong out-of-box baseline**: Stage1 achieves RÂ² = 0.81 with default settings
- âœ… **Refinement when needed**: Stage2 boost provides targeted improvements for challenging signals
- âœ… **Real-world sensor data**: Demonstrates effectiveness on production equipment measurements
- âœ… **Efficient training**: Both stages train quickly on standard hardware

**Trained Models**: [Available on Kaggle Models](https://www.kaggle.com/models/tianffan/industrial-digital-twin-by-transformer)

**Model File Locations**:
- **Stage1 Models**: Three files (`.pth`, `_config.json`, `_scaler.pkl`) are located in `saved_models/`
- **Stage2 Models**: Located in `saved_models/stage2_boost/`

**Note on Benchmarks**:
These results are provided as reference examples on specific datasets. This project prioritizes **practical applicability and ease of deployment** over competitive benchmark scores. Performance will vary based on your specific industrial application, sensor characteristics, and data quality. We encourage users to evaluate the framework on their own use cases.

---

#### ğŸŒ Atmospheric Physics Simulation Benchmark

**Dataset**: LEAP atmospheric physics simulation dataset

**Performance Results**:
- **Hardware**: Single NVIDIA A100 GPU (Google Colab)
- **Signals**: 164 output signals (excluding ptend_q family)
- **Stage1 (SST)**: RÂ² â‰ˆ 0.56
- **Stage2 Boost**: RÂ² â‰ˆ 0.58
- **Training**: No data augmentation applied

**Testing Notebook**: See `notebooks/transformer_boost_Leap_final.ipynb` (Author's testing file with comments in Chinese)

---

### ğŸ“Œ Performance Notes

**Variability Factors**:
Results may vary based on:
- Dataset characteristics (sensor correlation patterns, noise levels, signal complexity)
- Physical system properties (sensor spatial relationships, temporal dynamics)
- Model configuration (architecture size, training parameters)
- Application domain (manufacturing, energy, chemical processes, etc.)

**Best Results Observed**:
- **Highly correlated sensor systems**: RÂ² > 0.80 (e.g., rotating machinery)
- **Complex multi-physics systems**: RÂ² 0.55-0.65 (e.g., atmospheric simulation)

The framework shows particularly strong performance when sensor outputs have **clear physical interdependencies and spatial relationships**, which aligns with its core design philosophy.

---

### ğŸ¤ Community Contributions Welcome

We warmly encourage users to share their benchmark results! If you have applied this framework to your domain, please contribute:
- **Anonymized/desensitized datasets** from your industrial applications
- **Performance metrics** (RÂ², MAE, RMSE, etc.) and visualizations
- **Use case descriptions** and domain insights

Your contributions help build understanding of the framework's capabilities across diverse industrial scenarios. Please open an [issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues) or submit a pull request!

## ğŸ¤ Contributing

Thank you for your interest in this project! We truly value community engagement and feedback.

**Ways to Support This Project**:
- â­ **Give us a star!** It helps others discover this work and motivates continued development
- ğŸ› **Bug reports or suggestions?** Please feel free to open an [issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues)
- ğŸ’¬ **Ideas or questions?** We welcome discussions in issues or comments
- ğŸ“Š **Performance results?** Share your anonymized data and results - these are especially valuable!

**Current Status**: Due to time constraints, the author may not be able to immediately review and merge external pull requests. We sincerely appreciate your understanding.

**For major changes**: We kindly ask that you open an issue first to discuss your proposed changes before investing significant effort.

â±ï¸ **Response time**: The author will respond as time permits. Your patience is greatly appreciated.

Your understanding, patience, and contributions are greatly appreciated! ğŸ™

### Development Setup

```bash
# Clone repository
git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Install in development mode
pip install -e .

# Run tests (if available)
python -m pytest tests/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Transformer architecture based on "Attention Is All You Need" (Vaswani et al., 2017)
- Inspired by digital twin applications in industrial automation
- Built with PyTorch, Gradio, and the amazing open-source community

## ğŸ“ Contact

For questions, issues, or collaborations:
- **GitHub Issues**: [Create an issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues)
- **Email**: shvichenko11@gmail.com

## ğŸ”— Citation

If you use this work in your research, please cite:

```bibtex
@software{industrial_digital_twin_transformer,
  author = {FTF1990},
  title = {Industrial Digital Twin by Transformer},
  year = {2025},
  url = {https://github.com/FTF1990/Industrial-digital-twin-by-transformer}
}
```

## ğŸ—ºï¸ Roadmap

### v1.0 (Current) âœ…
- [x] Stage2 Boost training system
- [x] Intelligent RÂ² threshold selection
- [x] Ensemble model generation
- [x] Inference comparison tools
- [x] Enhanced Gradio interface

### v2.0 (Upcoming) ğŸš€

#### **Stage3 Temporal Oscillation Enhancement System** ğŸ•
The next evolution targeting temporal oscillation signal reconstruction:

- **Stage3 Temporal Oscillation Feature Extraction**:
  - Focus on signals with temporal oscillation characteristics (high-frequency pulsations, vibrations, etc.)
  - Current spatial-sequence Transformers can only capture mean features of temporal oscillations, unable to reconstruct oscillation patterns
  - Use temporal ML models or temporal Transformers for pure time-series feature extraction
  - Enhance and restore temporal oscillation characteristics inherent to the signals themselves

- **Final Residual Future Prediction**:
  - After Stage1 + Stage2 + Stage3, the final residuals are primarily devoid of spatial features
  - Enable pure time-series forecasting on final residuals for future timestep prediction
  - Suitable for applications requiring forward prediction capabilities

- **Signal Relationship Mask Editing** (Planned):
  - Maximize Transformer flexibility with input-output signal relationship masks
  - Apply engineering knowledge to mask non-directly-related factors
  - Better reconstruct real system behaviors by incorporating domain expertise
  - Enhance model accuracy through expert-guided feature relationships

- **Complete Spatial-Temporal Decomposition Architecture**:
  - **Stage1 (SST)**: Spatial sensor relationships and cross-sensor dependencies
  - **Stage2 (Boost)**: Spatial residual correction and secondary spatial patterns
  - **Stage3 (Temporal)**: Pure temporal oscillation features and time-series dynamics
  - **Final Goal**: Separate spatial and temporal features into hierarchical layers, capturing all predictable patterns except irreducible noise for universal digital twin applications

- **Hierarchical Feature Extraction Philosophy**:
  - Layer 1: Primary spatial sensor correlations (SST)
  - Layer 2: Residual spatial patterns (Stage2 Boost)
  - Layer 3: Temporal oscillation characteristics (Stage3 Temporal)
  - Final Residual: Irreducible stochastic noise + optional future prediction

This design aims to achieve **universal digital twin modeling** by systematically decomposing and capturing all predictable features across different domains.

---

**Made with â¤ï¸ for the Industrial AI Community**

---
---
---

<a name="ä¸­æ–‡"></a>

<div align="center">

## ğŸ“– Language / è¯­è¨€é€‰æ‹©

[![English](https://img.shields.io/badge/ğŸ‡ºğŸ‡¸_English-Click_Here-0078D4?style=for-the-badge)](#english)
[![ç®€ä½“ä¸­æ–‡](https://img.shields.io/badge/ğŸ‡¨ğŸ‡³_ç®€ä½“ä¸­æ–‡-ç‚¹å‡»è¿™é‡Œ-FF0000?style=for-the-badge)](#ä¸­æ–‡)

</div>

---

# Industrial Digital Twin by Transformer (åŸºäº Transformer çš„å·¥ä¸šæ•°å­—å­ªç”Ÿ)

**[English](#english)** | **[ä¸­æ–‡](#ä¸­æ–‡)**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **ä¸€ä¸ªåˆ›æ–°çš„åŸºäº Transformer çš„æ¡†æ¶ï¼Œä¸“ä¸ºå¤æ‚ç³»ç»Ÿä¸­çš„å·¥ä¸šæ•°å­—å­ªç”Ÿå»ºæ¨¡è®¾è®¡ï¼Œä½¿ç”¨åºåˆ—ä¼ æ„Ÿå™¨è¾“å‡ºå’Œå…ˆè¿›çš„æ®‹å·®æå‡è®­ç»ƒæ–¹æ³•ã€‚**

æœ¬é¡¹ç›®å¼•å…¥äº† Transformer æ¶æ„å’Œæ®‹å·®æå‡è®­ç»ƒæ–¹æ³•ï¼Œä¸“é—¨è®¾è®¡ç”¨äºé¢„æµ‹å·¥ä¸šæ•°å­—å­ªç”Ÿåº”ç”¨ä¸­çš„ä¼ æ„Ÿå™¨è¾“å‡ºã€‚ä¸ä¼ ç»Ÿæ–¹æ³•ä¸åŒï¼Œæˆ‘ä»¬çš„æ¨¡å‹åˆ©ç”¨å¤æ‚å·¥ä¸šç¯å¢ƒä¸­**å¤šä¼ æ„Ÿå™¨ç³»ç»Ÿçš„åºåˆ—ç‰¹æ€§**ï¼Œé€šè¿‡å¤šé˜¶æ®µä¼˜åŒ–å®ç°æ›´å¥½çš„é¢„æµ‹ç²¾åº¦ã€‚

---

**å¦‚æœæ‚¨è§‰å¾—è¿™ä¸ªé¡¹ç›®æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘ç»™å®ƒä¸€ä¸ª â­ starï¼æ‚¨çš„æ”¯æŒå¸®åŠ©æ›´å¤šäººå‘ç°è¿™é¡¹å·¥ä½œï¼Œå¹¶æ¿€åŠ±é¡¹ç›®æŒç»­å‘å±•ã€‚**

---

## ğŸŒŸ æ ¸å¿ƒåˆ›æ–°

**ä½¿ç”¨ Transformer è¿›è¡Œåºåˆ—ä¼ æ„Ÿå™¨é¢„æµ‹**ï¼šè¿™ä¸ªæ¡†æ¶å°† Transformer æ¶æ„åº”ç”¨äºå·¥ä¸šæ•°å­—å­ªç”Ÿä¸­åºåˆ—ä¼ æ„Ÿå™¨è¾“å‡ºé¢„æµ‹é—®é¢˜çš„æ¡†æ¶ã€‚è¯¥æ¨¡å‹å°†å¤šä¸ªä¼ æ„Ÿå™¨è§†ä¸ºä¸€ä¸ªåºåˆ—ï¼Œæ•è·ä¼ æ„Ÿå™¨ä¹‹é—´çš„ç©ºé—´å…³ç³»åŠå…¶æµ‹é‡å€¼çš„æ—¶é—´ä¾èµ–æ€§ã€‚

### ä¸ºä»€ä¹ˆè¿™å¾ˆé‡è¦

åœ¨å¤æ‚çš„å·¥ä¸šç³»ç»Ÿï¼ˆåˆ¶é€ å·¥å‚ã€åŒ–å·¥è¿‡ç¨‹ã€å‘ç”µç­‰ï¼‰ä¸­ï¼Œä¼ æ„Ÿå™¨ä¸æ˜¯å­¤ç«‹è¿è¡Œçš„ã€‚å®ƒä»¬çš„è¾“å‡ºå…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š
- **ç©ºé—´ç›¸å…³æ€§**ï¼šç‰©ç†é‚»è¿‘æ€§å’Œå·¥è‰ºæµç¨‹åˆ›å»ºäº†ä¾èµ–å…³ç³»
- **æ—¶é—´ä¾èµ–æ€§**ï¼šå†å²æµ‹é‡å€¼å½±å“å½“å‰å’Œæœªæ¥çš„è¯»æ•°
- **å±‚æ¬¡ç»“æ„**ï¼šä¸€äº›ä¼ æ„Ÿå™¨æµ‹é‡è¾¹ç•Œæ¡ä»¶ï¼Œè€Œå¦ä¸€äº›æµ‹é‡å†…éƒ¨çŠ¶æ€

ä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•ç‹¬ç«‹å¯¹å¾…ä¼ æ„Ÿå™¨æˆ–ä½¿ç”¨ç®€å•çš„æ—¶é—´åºåˆ—æ¨¡å‹ã€‚æˆ‘ä»¬åŸºäº Transformer çš„æ–¹æ³•**æ•è·ä¼ æ„Ÿå™¨ç›¸äº’å…³ç³»çš„å…¨éƒ¨å¤æ‚æ€§**ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

### æ¨¡å‹æ¶æ„

#### **StaticSensorTransformer (SST)**
- **ç”¨é€”**ï¼šå°†è¾¹ç•Œæ¡ä»¶ä¼ æ„Ÿå™¨æ˜ å°„åˆ°ç›®æ ‡ä¼ æ„Ÿå™¨é¢„æµ‹
- **æ¶æ„**ï¼šå…·æœ‰å­¦ä¹ ä½ç½®ç¼–ç çš„ä¼ æ„Ÿå™¨åºåˆ— Transformer
- **åˆ›æ–°ç‚¹**ï¼šå°†å›ºå®šä¼ æ„Ÿå™¨é˜µåˆ—è§†ä¸ºåºåˆ—ï¼ˆæ›¿ä»£ NLP ä¸­çš„è¯å…ƒåºåˆ—ï¼‰
- **åº”ç”¨åœºæ™¯**ï¼šå…·æœ‰å¤æ‚ä¼ æ„Ÿå™¨ç›¸äº’ä¾èµ–å…³ç³»çš„å·¥ä¸šç³»ç»Ÿ
- **ä¼˜åŠ¿**ï¼š
  - é€šè¿‡æ³¨æ„åŠ›æœºåˆ¶æ•è·ç©ºé—´ä¼ æ„Ÿå™¨å…³ç³»
  - å¿«é€Ÿè®­ç»ƒå’Œæ¨ç†
  - å­¦ä¹ ä¼ æ„Ÿå™¨ä¹‹é—´çš„ç‰©ç†å› æœå…³ç³»
  - éå¸¸é€‚åˆå·¥ä¸šæ•°å­—å­ªç”Ÿåº”ç”¨

### ğŸ†• å¢å¼ºå‹æ®‹å·®æå‡è®­ç»ƒç³»ç»Ÿ (v1.0)

#### **Stage2 æå‡è®­ç»ƒ** ğŸš€
- åœ¨ SST é¢„æµ‹æ®‹å·®ä¸Šè®­ç»ƒç¬¬äºŒé˜¶æ®µæ¨¡å‹
- è¿›ä¸€æ­¥ä¼˜åŒ–é¢„æµ‹ä»¥æé«˜å‡†ç¡®æ€§
- å¯é…ç½®çš„æ¶æ„å’Œè®­ç»ƒå‚æ•°
- è‡ªåŠ¨æ¨¡å‹ä¿å­˜å’Œç‰ˆæœ¬æ§åˆ¶

#### **æ™ºèƒ½ Delta RÂ² é˜ˆå€¼é€‰æ‹©** ğŸ¯
- è®¡ç®—æ¯ä¸ªä¿¡å·çš„ Delta RÂ² (RÂ²_ensemble - RÂ²_stage1)
- åŸºäº Delta RÂ² é˜ˆå€¼é€‰æ‹©æ€§åœ°åº”ç”¨ Stage2 ä¿®æ­£
- ç”Ÿæˆç»“åˆ SST + Stage2 çš„é›†æˆæ¨¡å‹
- ä¼˜åŒ–çš„æ€§èƒ½/æ•ˆç‡å¹³è¡¡
- ä»…å¯¹æœ‰æ˜¾è‘—æ”¹è¿›çš„ä¿¡å·ä½¿ç”¨ Stage2

#### **å…¨é¢çš„æ¨ç†å¯¹æ¯”** ğŸ“Š
- æ¯”è¾ƒé›†æˆæ¨¡å‹ä¸çº¯ SST æ¨¡å‹
- å¯è§†åŒ–æ‰€æœ‰è¾“å‡ºä¿¡å·çš„æ€§èƒ½æ”¹è¿›
- è¯¦ç»†çš„é€ä¿¡å·æŒ‡æ ‡åˆ†æï¼ˆMAEã€RMSEã€RÂ²ï¼‰
- CSV å¯¼å‡ºåŒ…å«é¢„æµ‹å€¼å’Œ RÂ² åˆ†æ•°
- äº¤äº’å¼ç´¢å¼•èŒƒå›´é€‰æ‹©

#### **å…¨ä¿¡å·å¯è§†åŒ–** ğŸ“ˆ
- æ¯ä¸ªè¾“å‡ºä¿¡å·çš„ç‹¬ç«‹é¢„æµ‹ vs å®é™…å€¼å¯¹æ¯”
- åŠ¨æ€å¸ƒå±€é€‚åº”ä¿¡å·æ•°é‡
- æ¯ä¸ªä¿¡å·æ˜¾ç¤º RÂ² åˆ†æ•°
- è½»æ¾è¯†åˆ«æ¨¡å‹æ”¹è¿›

### âš¡ è½»é‡åŒ–ä¸è¾¹ç¼˜å°±ç»ªæ¶æ„

#### **è¶…è½»é‡åŒ– Transformer è®¾è®¡**
å°½ç®¡åŸºäº Transformer æ¶æ„ï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¢«è®¾è®¡ä¸º**è¶…è½»é‡åŒ–å˜ä½“**ï¼Œåœ¨æœ€å°åŒ–è®¡ç®—éœ€æ±‚çš„åŒæ—¶ä¿æŒè‰¯å¥½æ€§èƒ½ï¼š

- **è¾¹ç¼˜è®¾å¤‡ä¼˜åŒ–**ï¼šåœ¨èµ„æºå—é™çš„ç¡¬ä»¶ä¸Šè®­ç»ƒå’Œéƒ¨ç½²
- **å¿«é€Ÿæ¨ç†**ï¼šå®æ—¶é¢„æµ‹ï¼Œå»¶è¿Ÿæä½
- **ä½å†…å­˜å ç”¨**ï¼šé€‚ç”¨äºåµŒå…¥å¼ç³»ç»Ÿçš„é«˜æ•ˆæ¨¡å‹æ¶æ„
- **å¿«é€Ÿè®­ç»ƒ**ï¼šå³ä½¿åœ¨æœ‰é™ç®—åŠ›ä¸‹ä¹Ÿèƒ½å¿«é€Ÿæ”¶æ•›

#### **Digital Twin Anythingï¼šé€šç”¨è¾¹ç¼˜éƒ¨ç½²** ğŸŒ

æˆ‘ä»¬çš„è®¾è®¡ç†å¿µå®ç°äº†**ä¸ªæ€§åŒ–çš„å•ä½“èµ„äº§æ•°å­—å­ªç”Ÿ**ï¼š

- **å•è½¦æ•°å­—å­ªç”Ÿ**ï¼šä¸ºæ¯è¾†æ±½è½¦å»ºç«‹ä¸“å±æ¨¡å‹
- **å•æœºç›‘æ§**ï¼šä¸ºæ¯å°å‘åŠ¨æœºå»ºç«‹ä¸ªæ€§åŒ–é¢„æµ‹æ¨¡å‹
- **è®¾å¤‡çº§å®šåˆ¶**ï¼šä»»ä½•åœ¨æµ‹è¯•å°æ¶ä¸‹æœ‰è¶³å¤Ÿä¼ æ„Ÿå™¨æ•°æ®çš„è®¾å¤‡ç³»ç»Ÿéƒ½å¯ä»¥æ‹¥æœ‰ä¸“å±çš„è½»é‡çº§æ•°å­—å­ªç”Ÿ
- **è‡ªåŠ¨åŒ–è¾¹ç¼˜æµç¨‹**ï¼šå®Œæ•´çš„è®­ç»ƒå’Œæ¨ç†æµç¨‹å¯éƒ¨ç½²åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Š

**æ„¿æ™¯**ï¼šä¸º**ä»»ä½•äº‹ç‰©**åˆ›å»ºè‡ªåŠ¨åŒ–çš„è½»é‡çº§æ•°å­—å­ªç”Ÿ - ä»å•ä¸ªæœºå™¨åˆ°æ•´æ¡ç”Ÿäº§çº¿ï¼Œå…¨éƒ¨è¿è¡Œåœ¨è¾¹ç¼˜ç¡¬ä»¶ä¸Šå¹¶å…·å¤‡æŒç»­å­¦ä¹ èƒ½åŠ›ã€‚

#### **æœªæ¥æ½œåŠ›ï¼šä»¿çœŸæ¨¡å‹ä»£ç†** ğŸ”¬

**é¢å‘è®¡ç®—æ•ˆç‡çš„å‰ç»æ€§åº”ç”¨å±•æœ›**ï¼š

æˆ‘ä»¬è½»é‡åŒ– Transformer æ¶æ„çš„ç‰¹æ€§å¼€å¯äº†ä¸€ä¸ªä»¤äººå…´å¥‹çš„æœªæ¥å¯èƒ½æ€§ï¼š
- å°†ä»¿çœŸä¸­çš„æ¯ä¸ªç½‘æ ¼åŒºåŸŸè§†ä¸ºè™šæ‹Ÿ"ä¼ æ„Ÿå™¨"
- æœ‰æ½œåŠ›ä½¿ç”¨è½»é‡çº§ Transformer å­¦ä¹ å¤æ‚çš„ä»¿çœŸè¡Œä¸º
- **å¯èƒ½ä»¥æä½ç®—åŠ›é€†å‘æ„å»ºæ˜‚è´µçš„ä»¿çœŸæ¨¡å‹**ï¼Œè®¡ç®—æˆæœ¬æœ‰æœ›é™ä½æ•°ä¸ªæ•°é‡çº§
- æœ‰æœ›åœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶å®ç°å®æ—¶ä»¿çœŸä»£ç†æ¨¡å‹
- å¯¹ CFDã€FEA ç­‰è®¡ç®—å¯†é›†å‹ä»¿çœŸå…·æœ‰åº”ç”¨å‰æ™¯

è¿™ä¸€æ–¹æ³•å¯èƒ½å¸¦æ¥æ–°çš„åº”ç”¨åœºæ™¯ï¼š
- è®¾è®¡è¿­ä»£è¿‡ç¨‹ä¸­çš„å®æ—¶ä»¿çœŸ
- æ™®åŠé«˜ä¿çœŸä»¿çœŸçš„ä½¿ç”¨
- åœ¨è¾¹ç¼˜è®¾å¤‡ä¸­åµŒå…¥å¤æ‚ç‰©ç†æ¨¡å‹
- åŠ é€Ÿæ•°å­—å­ªç”Ÿå¼€å‘å‘¨æœŸ

*æ³¨ï¼šè¿™ä»£è¡¨äº†ä¸€ä¸ªç†è®ºæ¡†æ¶å’Œæœªæ¥ç ”ç©¶æ–¹å‘ï¼Œå°šæœªåœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¾—åˆ°å……åˆ†éªŒè¯ã€‚*

### é™„åŠ åŠŸèƒ½

- âœ… **æ¨¡å—åŒ–è®¾è®¡**ï¼šæ˜“äºæ‰©å±•å’Œå®šåˆ¶
- âœ… **å…¨é¢çš„è®­ç»ƒæµç¨‹**ï¼šå†…ç½®æ•°æ®é¢„å¤„ç†ã€è®­ç»ƒå’Œè¯„ä¼°
- âœ… **äº¤äº’å¼ Gradio ç•Œé¢**ï¼šé€‚ç”¨äºæ‰€æœ‰è®­ç»ƒé˜¶æ®µçš„ç”¨æˆ·å‹å¥½å‹ Web ç•Œé¢
- âœ… **Jupyter Notebooks**ï¼šå®Œæ•´çš„æ•™ç¨‹å’Œç¤ºä¾‹
- âœ… **ç”Ÿäº§å°±ç»ª**ï¼šå¯å¯¼å‡ºæ¨¡å‹ç”¨äºéƒ¨ç½²
- âœ… **è¯¦å°½çš„æ–‡æ¡£**ï¼šæ¸…æ™°çš„ API æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
- âœ… **è‡ªåŠ¨åŒ–æ¨¡å‹ç®¡ç†**ï¼šæ™ºèƒ½æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼ˆå«é…ç½®ï¼‰

## ğŸ“Š ä½¿ç”¨åœºæ™¯

æœ¬æ¡†æ¶éå¸¸é€‚åˆï¼š

- **åˆ¶é€ ä¸šæ•°å­—å­ªç”Ÿ**ï¼šä»ä¼ æ„Ÿå™¨é˜µåˆ—é¢„æµ‹è®¾å¤‡çŠ¶æ€
- **åŒ–å·¥è¿‡ç¨‹ç›‘æ§**ï¼šå»ºæ¨¡ååº”å™¨ä¸­çš„å¤æ‚ä¼ æ„Ÿå™¨äº¤äº’
- **å‘ç”µå‚ä¼˜åŒ–**ï¼šé¢„æµ‹æ¶¡è½®æœºå’Œå‘ç”µæœºçŠ¶å†µ
- **HVAC ç³»ç»Ÿ**ï¼šé¢„æµ‹æ¸©åº¦å’Œå‹åŠ›åˆ†å¸ƒ
- **é¢„æµ‹æ€§ç»´æŠ¤**ï¼šä»ä¼ æ„Ÿå™¨æ¨¡å¼ä¸­æ—©æœŸæ£€æµ‹å¼‚å¸¸
- **è´¨é‡æ§åˆ¶**ï¼šä»å·¥è‰ºä¼ æ„Ÿå™¨é¢„æµ‹äº§å“è´¨é‡

## ğŸ—ï¸ æ¶æ„æ¦‚è¿°

### ğŸ”‘ æ ¸å¿ƒåˆ›æ–°ï¼šä¼ æ„Ÿå™¨ä½œä¸ºåºåˆ—å…ƒç´ 

**ä¼ ç»Ÿ NLP Transformer vs. SSTï¼ˆæˆ‘ä»¬çš„åˆ›æ–°ï¼‰**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  NLP Transformerï¼ˆä¼ ç»Ÿï¼‰                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥:  [The, cat, sits, on, the, mat]  â† å•è¯ä½œä¸ºè¯å…ƒ          â”‚
â”‚ åµŒå…¥:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ,   Eâ‚„,  Eâ‚…,  Eâ‚†]  â† è¯åµŒå…¥                â”‚
â”‚ ä½ç½®:  [Pâ‚,  Pâ‚‚,  Pâ‚ƒ,   Pâ‚„,  Pâ‚…,  Pâ‚†]  â† æ—¶é—´é¡ºåº              â”‚
â”‚ æ³¨æ„åŠ›: å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                              â¬‡ï¸  åˆ›æ–°ç‚¹  â¬‡ï¸

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SST - ä¼ æ„Ÿå™¨åºåˆ— Transformerï¼ˆæˆ‘ä»¬çš„ï¼‰             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¾“å…¥:  [Sâ‚,  Sâ‚‚,  Sâ‚ƒ, ..., Sâ‚™]  â† å›ºå®šä¼ æ„Ÿå™¨é˜µåˆ—               â”‚
â”‚         (æ¸©åº¦, å‹åŠ›, æµé‡, ...)                                 â”‚
â”‚ åµŒå…¥:  [Eâ‚,  Eâ‚‚,  Eâ‚ƒ, ..., Eâ‚™]  â† ä¼ æ„Ÿå™¨å€¼åµŒå…¥                 â”‚
â”‚ ä½ç½®:  [Pâ‚,  Pâ‚‚,  Pâ‚ƒ, ..., Pâ‚™]  â† ç©ºé—´ä½ç½®                     â”‚
â”‚ æ³¨æ„åŠ›: ç‰©ç†å› æœå…³ç³»å’Œä¼ æ„Ÿå™¨ç›¸äº’ä¾èµ–å…³ç³»                        â”‚
â”‚                                                                  â”‚
â”‚ å…³é”®å·®å¼‚ï¼š                                                       â”‚
â”‚ â€¢ å›ºå®šåºåˆ—é•¿åº¦ï¼ˆN ä¸ªä¼ æ„Ÿå™¨é¢„å…ˆç¡®å®šï¼‰                            â”‚
â”‚ â€¢ ä½ç½® = ä¼ æ„Ÿå™¨ä½ç½®ï¼Œè€Œéæ—¶é—´é¡ºåº                               â”‚
â”‚ â€¢ æ³¨æ„åŠ›å­¦ä¹ è·¨ä¼ æ„Ÿå™¨ç‰©ç†å…³ç³»                                    â”‚
â”‚ â€¢ é’ˆå¯¹å·¥ä¸šç³»ç»Ÿçš„é¢†åŸŸä¸“ç”¨è®¾è®¡                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ¯ SST æ¶æ„æ·±å…¥è§£æ

```
ç‰©ç†ä¼ æ„Ÿå™¨é˜µåˆ—: [Sensorâ‚, Sensorâ‚‚, ..., Sensorâ‚™]
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ä¼ æ„Ÿå™¨åµŒå…¥å±‚                                  â”‚
â”‚  â€¢ å°†æ¯ä¸ªæ ‡é‡ä¼ æ„Ÿå™¨è¯»æ•°æŠ•å½±åˆ° d_model ç»´åº¦                      â”‚
â”‚  â€¢ æ¯ä¸ªä¼ æ„Ÿå™¨è·å¾—è‡ªå·±çš„åµŒå…¥å˜æ¢                                  â”‚
â”‚  â€¢ è¾“å…¥: (batch, N_sensors) â†’ è¾“å‡º: (batch, N_sensors, d_model) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               å¯å­¦ä¹ ä½ç½®ç¼–ç                                      â”‚
â”‚  â€¢ ä¸ NLP ä¸åŒï¼šç¼–ç ç©ºé—´ä¼ æ„Ÿå™¨ä½ç½®                              â”‚
â”‚  â€¢ å­¦ä¹ ä¼ æ„Ÿå™¨ä½ç½®é‡è¦æ€§ï¼ˆä¾‹å¦‚ï¼Œè¿›å£ vs å‡ºå£ï¼‰                   â”‚
â”‚  â€¢ å½¢çŠ¶: (N_sensors, d_model) - æ¯ä¸ªä¼ æ„Ÿå™¨ä¸€ä¸ª                 â”‚
â”‚  â€¢ æ·»åŠ åˆ°åµŒå…¥ä¸­: Embed + PosEncode                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ å¤´ 1: å­¦ä¹ æ¸©åº¦-å‹åŠ›å…³ç³»                                  â”‚  â”‚
â”‚  â”‚ å¤´ 2: å­¦ä¹ æµé‡-é€Ÿåº¦ç›¸å…³æ€§                                â”‚  â”‚
â”‚  â”‚ å¤´ 3: å­¦ä¹ ç©ºé—´é‚»è¿‘æ•ˆåº”                                   â”‚  â”‚
â”‚  â”‚ ...                                                      â”‚  â”‚
â”‚  â”‚ å¤´ N: å­¦ä¹ ç³»ç»Ÿçº§ä¾èµ–å…³ç³»                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â€¢ æ•è·å¤æ‚çš„éçº¿æ€§ä¼ æ„Ÿå™¨äº¤äº’                                   â”‚
â”‚  â€¢ æ³¨æ„åŠ›æƒé‡æ­ç¤ºä¼ æ„Ÿå™¨é‡è¦æ€§                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Transformer ç¼–ç å™¨å †æ ˆ                         â”‚
â”‚  å±‚ 1: æ³¨æ„åŠ› + FFN + æ®‹å·®                                      â”‚
â”‚  å±‚ 2: æ³¨æ„åŠ› + FFN + æ®‹å·®                                      â”‚
â”‚  ...                                                             â”‚
â”‚  å±‚ L: æ³¨æ„åŠ› + FFN + æ®‹å·®                                      â”‚
â”‚  â€¢ æ¯ä¸€å±‚ä¼˜åŒ–ä¼ æ„Ÿå™¨å…³ç³»ç†è§£                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              å…¨å±€æ± åŒ–ï¼ˆåºåˆ—èšåˆï¼‰                                â”‚
â”‚  â€¢ å¯¹ä¼ æ„Ÿå™¨åºåˆ—è¿›è¡Œè‡ªé€‚åº”å¹³å‡æ± åŒ–                               â”‚
â”‚  â€¢ èšåˆæ¥è‡ªæ‰€æœ‰ä¼ æ„Ÿå™¨çš„ä¿¡æ¯                                     â”‚
â”‚  â€¢ è¾“å‡º: (batch, d_model) - å›ºå®šå¤§å°è¡¨ç¤º                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è¾“å‡ºæŠ•å½±å±‚                                    â”‚
â”‚  â€¢ å°†èšåˆè¡¨ç¤ºæŠ•å½±åˆ°ç›®æ ‡ä¼ æ„Ÿå™¨å€¼                                 â”‚
â”‚  â€¢ çº¿æ€§å˜æ¢: d_model â†’ N_target_sensors                        â”‚
â”‚  â€¢ æœ€ç»ˆé¢„æµ‹: (batch, N_target_sensors)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â†“
              ç›®æ ‡ä¼ æ„Ÿå™¨é¢„æµ‹
```

### ğŸ“Š Stage2 æ®‹å·®æå‡ç³»ç»Ÿ

å»ºç«‹åœ¨ SST ä¹‹ä¸Šï¼ŒStage2 ç³»ç»Ÿè¿›ä¸€æ­¥ä¼˜åŒ–é¢„æµ‹ï¼š

```
æ­¥éª¤ 1: åŸºç¡€ SST æ¨¡å‹
   è¾¹ç•Œä¼ æ„Ÿå™¨ â†’ [SST] â†’ é¢„æµ‹ + æ®‹å·®

æ­¥éª¤ 2: Stage2 æ®‹å·®æ¨¡å‹
   è¾¹ç•Œä¼ æ„Ÿå™¨ â†’ [SSTâ‚‚] â†’ æ®‹å·®ä¿®æ­£

æ­¥éª¤ 3: æ™ºèƒ½ Delta RÂ² é€‰æ‹©
   å¯¹äºæ¯ä¸ªç›®æ ‡ä¿¡å·:
     Delta RÂ² = RÂ²_ensemble - RÂ²_stage1
     if Delta RÂ² > é˜ˆå€¼: åº”ç”¨ Stage2 ä¿®æ­£
     else: ä½¿ç”¨åŸºç¡€ SST é¢„æµ‹

æ­¥éª¤ 4: æœ€ç»ˆé›†æˆæ¨¡å‹
   é¢„æµ‹ = Stage1 é¢„æµ‹ + é€‰æ‹©æ€§ Stage2 ä¿®æ­£

```

## ğŸ”§ å®‰è£…

### ä½¿ç”¨ Google Colab å¿«é€Ÿå¼€å§‹

```bash
# å…‹éš†ä»“åº“
!git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
%cd Industrial-digital-twin-by-transformer

# å®‰è£…ä¾èµ–
!pip install -r requirements.txt
```

### æœ¬åœ°å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python -m venv venv
source venv/bin/activate  # Windows ç³»ç»Ÿ: venv\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

## ğŸ“š å¿«é€Ÿå…¥é—¨

### 1. å‡†å¤‡æ•°æ®

å°†æ‚¨çš„ CSV ä¼ æ„Ÿå™¨æ•°æ®æ–‡ä»¶æ”¾åœ¨ `data/raw/` æ–‡ä»¶å¤¹ä¸­ã€‚æ‚¨çš„ CSV åº”è¯¥å…·æœ‰ï¼š
- æ¯è¡Œä»£è¡¨ä¸€ä¸ªæ—¶é—´æ­¥
- æ¯åˆ—ä»£è¡¨ä¸€ä¸ªä¼ æ„Ÿå™¨æµ‹é‡å€¼
- ï¼ˆå¯é€‰ï¼‰ç¬¬ä¸€åˆ—å¯ä»¥æ˜¯æ—¶é—´æˆ³

CSV ç»“æ„ç¤ºä¾‹ï¼š
```csv
timestamp,sensor_1,sensor_2,sensor_3,...,sensor_n
2025-01-01 00:00:00,23.5,101.3,45.2,...,78.9
2025-01-01 00:00:01,23.6,101.4,45.1,...,79.0
...
```

### 2. ä½¿ç”¨ Jupyter Notebook è®­ç»ƒ Stage1 æ¨¡å‹ï¼ˆåŸºç¡€è®­ç»ƒï¼‰

æœ¬èŠ‚æ¼”ç¤º**åŸºç¡€ Stage1 (SST) æ¨¡å‹è®­ç»ƒ**ï¼Œç”¨äºå­¦ä¹ ä¼ æ„Ÿå™¨é¢„æµ‹å»ºæ¨¡çš„åŸºç¡€çŸ¥è¯†ã€‚

**æ³¨æ„**ï¼šNotebook æä¾›äº†ç†è§£ SST æ¶æ„å’ŒåŸºç¡€è®­ç»ƒè¿‡ç¨‹çš„åŸºç¡€ã€‚å¦‚éœ€å®Œæ•´çš„ Stage2 æå‡è®­ç»ƒå’Œé›†æˆæ¨¡å‹ç”ŸæˆåŠŸèƒ½ï¼Œè¯·ä½¿ç”¨å¢å¼ºå‹ Gradio ç•Œé¢ï¼ˆç¬¬3èŠ‚ï¼‰ã€‚

**å¯ç”¨çš„ Notebooks**ï¼š
- `notebooks/Train and run model with demo data and your own data with gradio interface.ipynb` - åˆå­¦è€…å¿«é€Ÿå…¥é—¨æ•™ç¨‹
- `notebooks/transformer_boost_Leap_final.ipynb` - é«˜çº§ç¤ºä¾‹ï¼šåœ¨ LEAP æ•°æ®é›†ä¸Šçš„å®Œæ•´ Stage1 + Stage2 è®­ç»ƒï¼ˆä½œè€…æµ‹è¯•æ–‡ä»¶ï¼Œæ³¨é‡Šä¸ºä¸­æ–‡ï¼‰

**åŸºç¡€è®­ç»ƒç¤ºä¾‹**ï¼ˆç”¨äºæ‚¨è‡ªå·±çš„æ•°æ®ï¼‰ï¼š

```python
from models.static_transformer import StaticSensorTransformer
from src.data_loader import SensorDataLoader
from src.trainer import ModelTrainer

# åŠ è½½æ•°æ®
data_loader = SensorDataLoader(data_path='data/raw/your_data.csv')

# é…ç½®ä¿¡å·
boundary_signals = ['sensor_1', 'sensor_2', 'sensor_3']  # è¾“å…¥
target_signals = ['sensor_4', 'sensor_5']  # è¦é¢„æµ‹çš„è¾“å‡º

# å‡†å¤‡æ•°æ®
data_splits = data_loader.prepare_data(boundary_signals, target_signals)

# åˆ›å»ºå’Œè®­ç»ƒ Stage1 SST æ¨¡å‹
model = StaticSensorTransformer(
    num_boundary_sensors=len(boundary_signals),
    num_target_sensors=len(target_signals)
)

trainer = ModelTrainer(model, device='cuda')
history = trainer.train(train_loader, val_loader)

# ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
torch.save(model.state_dict(), 'saved_models/my_sst_model.pth')
```

**åœ¨ Stage1 ä¸­æ‚¨å°†å­¦åˆ°**ï¼š
- åŠ è½½å’Œé¢„å¤„ç†ä¼ æ„Ÿå™¨æ•°æ®
- é…ç½®è¾¹ç•Œä¼ æ„Ÿå™¨å’Œç›®æ ‡ä¼ æ„Ÿå™¨
- è®­ç»ƒé™æ€ä¼ æ„Ÿå™¨ Transformer (SST)
- åŸºç¡€æ¨¡å‹è¯„ä¼°å’Œé¢„æµ‹

**å¦‚éœ€å®Œæ•´åŠŸèƒ½**ï¼ˆStage2 æå‡ + é›†æˆæ¨¡å‹ï¼‰ï¼Œè¯·ç»§ç»­ç¬¬3èŠ‚ã€‚

### 3. ä½¿ç”¨å¢å¼ºå‹ Gradio ç•Œé¢ï¼ˆå®Œæ•´ Stage1 + Stage2 è®­ç»ƒï¼‰

**Gradio UI æ¼”ç¤ºè§†é¢‘**ï¼šå³å°†æ¨å‡º

#### **Jupyter Notebook å…¥é—¨æ•™ç¨‹**

æœ‰å…³åˆ†æ­¥æŒ‡å—ï¼Œè¯·å‚é˜…ï¼š
- `notebooks/Train and run model with demo data and your own data with gradio interface.ipynb`

è¯¥ notebook æ¼”ç¤ºäº†ï¼š
- ä» Kaggle ä¸‹è½½æ¼”ç¤ºæ•°æ®ï¼ˆpower-gen-machine æ•°æ®é›†ï¼‰
- è®¾ç½® Gradio ç•Œé¢
- ä½¿ç”¨æ¼”ç¤ºæ•°æ®æˆ–æ‚¨è‡ªå·±çš„è‡ªå®šä¹‰æ•°æ®è¿›è¡Œè®­ç»ƒ

åªéœ€æŒ‰ç…§ notebook æ­¥éª¤æ“ä½œå³å¯å¼€å§‹ä½¿ç”¨å®Œæ•´å·¥ä½œæµç¨‹ã€‚

#### **å®Œæ•´å·¥ä½œæµç¨‹**

å¢å¼ºå‹ç•Œé¢æä¾›**å®Œæ•´çš„ç«¯åˆ°ç«¯å·¥ä½œæµç¨‹**ï¼š
- ğŸ“Š **Tab 1: æ•°æ®åŠ è½½** - åˆ·æ–°å¹¶é€‰æ‹©æ¼”ç¤ºæ•°æ®ï¼ˆ`data.csv`ï¼‰æˆ–ä¸Šä¼ æ‚¨è‡ªå·±çš„ CSV
- ğŸ¯ **Tab 2: ä¿¡å·é…ç½®ä¸ Stage1 è®­ç»ƒ** - åˆ·æ–°ï¼ŒåŠ è½½ä¿¡å·é…ç½®ï¼Œé€‰æ‹©å‚æ•°ï¼Œè®­ç»ƒåŸºç¡€ SST æ¨¡å‹
- ğŸ”¬ **Tab 3: æ®‹å·®æå–** - ä» Stage1 æ¨¡å‹ä¸­æå–å’Œåˆ†æé¢„æµ‹è¯¯å·®
- ğŸš€ **Tab 4: Stage2 æå‡è®­ç»ƒ** - åœ¨æ®‹å·®ä¸Šè®­ç»ƒç¬¬äºŒé˜¶æ®µæ¨¡å‹è¿›è¡Œè¯¯å·®ä¿®æ­£
- ğŸ¯ **Tab 5: é›†æˆæ¨¡å‹ç”Ÿæˆ** - åŸºäºæ™ºèƒ½ Delta RÂ² é˜ˆå€¼çš„æ¨¡å‹ç»„åˆ
- ğŸ“Š **Tab 6: æ¨ç†å¯¹æ¯”** - æ¯”è¾ƒ Stage1 SST vs. é›†æˆæ¨¡å‹æ€§èƒ½å¹¶å¯è§†åŒ–
- ğŸ’¾ **Tab 7: å¯¼å‡º** - è‡ªåŠ¨æ¨¡å‹ä¿å­˜ï¼ˆå«å®Œæ•´é…ç½®ï¼‰

**è¿™æ˜¯ä½“éªŒæ¡†æ¶å®Œæ•´åŠŸèƒ½çš„æ¨èæ–¹å¼**ï¼ŒåŒ…æ‹¬ï¼š
- ä½¿ç”¨æ¼”ç¤ºæ•°æ®çš„è‡ªåŠ¨åŒ–å¤šé˜¶æ®µè®­ç»ƒæµç¨‹
- æ™ºèƒ½çš„é€ä¿¡å· Stage2 é€‰æ‹©
- å…¨é¢çš„æ€§èƒ½æŒ‡æ ‡å’Œå¯è§†åŒ–
- ç”Ÿäº§å°±ç»ªçš„é›†æˆæ¨¡å‹ç”Ÿæˆ

**ä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®**ï¼š
åªéœ€å°†æ‚¨çš„ CSV æ–‡ä»¶æ”¾åœ¨ `data/` æ–‡ä»¶å¤¹ä¸­ï¼Œåœ¨ Tab 1 ä¸­åˆ·æ–°å¹¶é€‰æ‹©æ‚¨çš„æ–‡ä»¶ã€‚ç¡®ä¿æ‚¨çš„ CSV éµå¾ªä¸æ¼”ç¤ºæ•°æ®ç›¸åŒçš„æ ¼å¼ï¼ˆæ—¶é—´æ­¥ä½œä¸ºè¡Œï¼Œä¼ æ„Ÿå™¨ä½œä¸ºåˆ—ï¼‰ã€‚ç„¶ååœ¨ Tab 2 ä¸­é…ç½®æ‚¨è‡ªå·±çš„è¾“å…¥/è¾“å‡ºä¿¡å·ã€‚

**å¿«é€Ÿå…¥é—¨æŒ‡å—**ï¼šå‚è§ `docs/QUICKSTART.md` è·å– 5 åˆ†é’Ÿæ•™ç¨‹

## ğŸ“– æ–‡æ¡£

### é¡¹ç›®ç»“æ„

```
Industrial-digital-twin-by-transformer/
â”œâ”€â”€ models/                      # æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ static_transformer.py    # SST (StaticSensorTransformer)
â”‚   â”œâ”€â”€ utils.py                # å·¥å…·å‡½æ•°
â”‚   â””â”€â”€ saved/                  # ä¿å­˜çš„æ¨¡å‹æ£€æŸ¥ç‚¹
â”œâ”€â”€ saved_models/               # è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆå«é…ç½®ï¼‰
â”‚   â”œâ”€â”€ StaticSensorTransformer_*.pth   # SST æ¨¡å‹
â”‚   â”œâ”€â”€ stage2_boost/           # Stage2 æ®‹å·®æ¨¡å‹
â”‚   â”œâ”€â”€ ensemble/               # é›†æˆæ¨¡å‹é…ç½®
â”‚   â””â”€â”€ tft_models/            # TFT æ¨¡å‹ï¼ˆå¦‚æœä½¿ç”¨ï¼‰
â”œâ”€â”€ src/                        # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py         # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
â”‚   â”œâ”€â”€ trainer.py             # è®­ç»ƒæµç¨‹
â”‚   â””â”€â”€ inference.py           # æ¨ç†å¼•æ“
â”œâ”€â”€ docs/                       # æ–‡æ¡£
â”‚   â”œâ”€â”€ ENHANCED_VERSION_README.md  # å¢å¼ºåŠŸèƒ½æŒ‡å—
â”‚   â”œâ”€â”€ UPDATE_NOTES.md        # è¯¦ç»†æ›´æ–°è¯´æ˜
â”‚   â”œâ”€â”€ QUICKSTART.md          # 5 åˆ†é’Ÿå¿«é€Ÿå…¥é—¨
â”‚   â””â”€â”€ FILE_MANIFEST.md       # æ–‡ä»¶ç»“æ„æŒ‡å—
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â”œâ”€â”€ transformer_boost_Leap_final.ipynb  # ä½œè€…åœ¨ LEAP æ•°æ®é›†ä¸Šçš„æµ‹è¯•æ–‡ä»¶ï¼ˆæ³¨é‡Šä¸ºä¸­æ–‡ï¼‰
â”‚   â””â”€â”€ Train and run model with demo data and your own data with gradio interface.ipynb  # å¿«é€Ÿå…¥é—¨æ•™ç¨‹
â”œâ”€â”€ data/                      # æ•°æ®æ–‡ä»¶å¤¹
â”‚   â”œâ”€â”€ raw/                   # å°†æ‚¨çš„ CSV æ–‡ä»¶æ”¾åœ¨è¿™é‡Œ
â”‚   â””â”€â”€ residuals_*.csv       # æå–çš„æ®‹å·®
â”œâ”€â”€ examples/                  # ç¤ºä¾‹è„šæœ¬
â”‚   â””â”€â”€ quick_start.py        # å¿«é€Ÿå…¥é—¨ç¤ºä¾‹
â”œâ”€â”€ configs/                   # é…ç½®æ–‡ä»¶
â”œâ”€â”€ archive/                   # å½’æ¡£çš„æ—§æ–‡ä»¶
â”‚   â”œâ”€â”€ gradio_app.py         # æ—§çš„ç®€å•ç•Œé¢
â”‚   â”œâ”€â”€ gradio_full_interface.py  # æ—§çš„å®Œæ•´ç•Œé¢
â”‚   â””â”€â”€ hybrid_transformer.py  # å·²å¼ƒç”¨çš„ HST æ¨¡å‹
â”œâ”€â”€ gradio_sensor_transformer_app.py # ğŸ†• å¢å¼ºå‹ Gradio åº”ç”¨
â”œâ”€â”€ requirements.txt          # Python ä¾èµ–
â”œâ”€â”€ setup.py                  # åŒ…è®¾ç½®
â”œâ”€â”€ LICENSE                   # MIT è®¸å¯è¯
â””â”€â”€ README.md                # è‹±æ–‡è¯´æ˜æ–‡ä»¶
```

### æ¨¡å‹ API

#### StaticSensorTransformer (SST)

```python
from models.static_transformer import StaticSensorTransformer

model = StaticSensorTransformer(
    num_boundary_sensors=10,    # è¾“å…¥ä¼ æ„Ÿå™¨æ•°é‡
    num_target_sensors=5,       # è¾“å‡ºä¼ æ„Ÿå™¨æ•°é‡
    d_model=128,                # æ¨¡å‹ç»´åº¦
    nhead=8,                    # æ³¨æ„åŠ›å¤´æ•°é‡
    num_layers=3,               # Transformer å±‚æ•°
    dropout=0.1                 # Dropout ç‡
)

# å‰å‘ä¼ æ’­
predictions = model(boundary_conditions)  # å½¢çŠ¶: (batch_size, num_target_sensors)
```

#### Stage2 æ®‹å·®æå‡è®­ç»ƒ

```python
# æ­¥éª¤ 1: è®­ç»ƒåŸºç¡€ SST æ¨¡å‹
base_model = StaticSensorTransformer(...)
# ... è®­ç»ƒåŸºç¡€æ¨¡å‹ ...

# æ­¥éª¤ 2: æå–æ®‹å·®
residuals = true_values - base_model_predictions

# æ­¥éª¤ 3: åœ¨æ®‹å·®ä¸Šè®­ç»ƒ Stage2 æ¨¡å‹
stage2_model = StaticSensorTransformer(...)
# ... åœ¨æ®‹å·®ä¸Šè®­ç»ƒ stage2 ...

# æ­¥éª¤ 4: ä½¿ç”¨æ™ºèƒ½ Delta RÂ² é€‰æ‹©ç”Ÿæˆé›†æˆ
for signal_idx in range(num_signals):
    r2_base = calculate_r2(true_values[:, signal_idx], base_predictions[:, signal_idx])
    r2_ensemble = calculate_r2(true_values[:, signal_idx], base_pred[:, signal_idx] + stage2_pred[:, signal_idx])
    delta_r2 = r2_ensemble - r2_base

    if delta_r2 > threshold:  # ä¾‹å¦‚, threshold=0.05 (5% æ”¹è¿›)
        # ä½¿ç”¨ Stage2 ä¿®æ­£ï¼ˆæ˜¾è‘—æ”¹è¿›ï¼‰
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx] + stage2_pred[:, signal_idx]
    else:
        # ä¿æŒåŸºç¡€é¢„æµ‹ï¼ˆæ— æ˜¾è‘—æ”¹è¿›ï¼‰
        ensemble_pred[:, signal_idx] = base_pred[:, signal_idx]
```

**æ³¨æ„**ï¼šå¢å¼ºå‹ Gradio ç•Œé¢ï¼ˆ`gradio_sensor_transformer_app.py`ï¼‰è‡ªåŠ¨åŒ–äº†æ•´ä¸ªå·¥ä½œæµç¨‹ã€‚

## ğŸ¯ æ€§èƒ½

### åŸºå‡†æµ‹è¯•ç»“æœ

#### ğŸ­ å·¥ä¸šæ—‹è½¬æœºæ¢°æ¡ˆä¾‹ç ”ç©¶

**æ•°æ®é›†**ï¼š[å‘ç”µæœºæ¢°ä¼ æ„Ÿå™¨æ•°æ®](https://www.kaggle.com/datasets/tianffan/power-gen-machine)

**åº”ç”¨é¢†åŸŸ**ï¼šçœŸå®ä¸–ç•Œçš„å°–ç«¯å‘ç”µæ—‹è½¬æœºæ¢°
- å¤æ‚å·¥ä¸šè®¾å¤‡çš„å¤šä¼ æ„Ÿå™¨ç³»ç»Ÿç›‘æµ‹
- ç”Ÿäº§ç¯å¢ƒçš„é«˜é¢‘æ“ä½œæ•°æ®
- å·¥ä¸šæ•°å­—å­ªç”Ÿåº”ç”¨çš„ä»£è¡¨æ€§æ¡ˆä¾‹

**æ•°æ®é›†ç‰¹å¾**ï¼š
- **æ¥æº**ï¼šçœŸå®å·¥ä¸šè®¾å¤‡ä¼ æ„Ÿå™¨é˜µåˆ—
- **å¤æ‚åº¦**ï¼šé«˜æ€§èƒ½æ—‹è½¬ç³»ç»Ÿä¸­çš„å¤šä¼ æ„Ÿå™¨ç›¸äº’ä¾èµ–å…³ç³»
- **è§„æ¨¡**ï¼šè¦†ç›–å…³é”®å‚æ•°çš„å®Œæ•´ä¼ æ„Ÿå™¨å¥—ä»¶
- **è´¨é‡**ï¼šç”Ÿäº§çº§ä¼ æ„Ÿå™¨æµ‹é‡æ•°æ®

**æ€§èƒ½ç»“æœ**ï¼ˆæµ‹è¯•é›†ï¼‰ï¼š

| æŒ‡æ ‡ | Stage1 (SST) | Stage1+Stage2 é›†æˆ | æ”¹è¿›å¹…åº¦ |
|------|--------------|---------------------|----------|
| **RÂ²** | 0.8101 | **0.9014** | +11.3% |
| **MAE** | 1.56 | **1.24** | -20.2% |
| **RMSE** | 3.89 | **3.57** | -8.3% |

**é…ç½®**ï¼š
- **æ•°æ®é›†**ï¼š89 ä¸ªç›®æ ‡ä¿¡å·ï¼Œ21.7 ä¸‡æ ·æœ¬
- **Stage1**ï¼š50 epochsï¼Œé»˜è®¤è¶…å‚æ•°
- **Stage2**ï¼šé€‰æ‹©æ€§å¢å¼º 36/89 ä¸ªä¿¡å·ï¼ˆDelta RÂ² é˜ˆå€¼ï¼š0.03ï¼‰
- **ç¡¬ä»¶**ï¼šå•å¡ NVIDIA A100 GPU
- **è®­ç»ƒ**ï¼šæ— æ•°æ®å¢å¼ºï¼Œæ— ç‰¹æ®Šè°ƒå‚

**è®­ç»ƒæ¨è**ï¼ˆåŸºäºå®è·µç»éªŒï¼‰ï¼š

ä»¥ä¸Šç»“æœä½¿ç”¨é»˜è®¤è¶…å‚æ•°è·å¾—ã€‚ç„¶è€Œï¼Œé€šè¿‡ä»¥ä¸‹å‚æ•°è°ƒä¼˜ç­–ç•¥**é€šå¸¸å¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½**ï¼š
- ğŸ“‰ **æ›´ä½çš„å­¦ä¹ ç‡**ï¼šè¾ƒå°çš„å­¦ä¹ ç‡ï¼ˆä¾‹å¦‚ 0.00003 vs. é»˜è®¤ 0.0001ï¼‰é€šå¸¸èƒ½å¸¦æ¥æ›´å¥½çš„æ”¶æ•›
- â±ï¸ **æ›´é«˜çš„è°ƒåº¦å™¨è€å¿ƒå€¼**ï¼šå¢åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨è€å¿ƒå€¼ï¼ˆä¾‹å¦‚ 8 vs. é»˜è®¤ 3ï¼‰å…è®¸æ›´ç¨³å®šçš„è®­ç»ƒ
- ğŸ“Š **æ›´é«˜çš„è¡°å‡å› å­**ï¼šæ›´é«˜çš„å­¦ä¹ ç‡è¡°å‡å› å­å¯å‡å°‘æ¿€è¿›çš„å­¦ä¹ ç‡ä¸‹é™
- ğŸ”„ **æ›´å¤šçš„è®­ç»ƒè½®æ•°**ï¼šä½¿ç”¨ä¸Šè¿°è®¾ç½®è®­ç»ƒæ›´å¤šè½®æ¬¡é€šå¸¸èƒ½æé«˜æœ€ç»ˆæ€§èƒ½

è¿™äº›è°ƒæ•´æœ‰åŠ©äºå®ç°æ›´å¹³æ»‘çš„æ”¶æ•›å’Œæ›´å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå¤æ‚çš„å·¥ä¸šä¼ æ„Ÿå™¨ç³»ç»Ÿã€‚

**Stage2 æ™ºèƒ½é€‰æ‹©**ï¼š
- **36 ä¸ªä¿¡å·** é€‰æ‹© Stage2 æ ¡æ­£ï¼ˆè§‚å¯Ÿåˆ°æ˜¾è‘—æ”¹è¿›ï¼‰
- **53 ä¸ªä¿¡å·** ä¿æŒ Stage1 é¢„æµ‹ï¼ˆå·²è¡¨ç°è‰¯å¥½ï¼‰
- è‡ªé€‚åº”ç­–ç•¥å¹³è¡¡æ€§èƒ½æå‡ä¸è®¡ç®—æ•ˆç‡

**ä¿¡å·æ”¹è¿›ç¤ºä¾‹**ï¼ˆStage1 â†’ é›†æˆï¼‰ï¼š
- æŒ¯åŠ¨ä¼ æ„Ÿå™¨ï¼šRÂ² -0.13 â†’ 0.26ï¼Œ-0.55 â†’ 0.47ï¼ˆæŒ‘æˆ˜æ€§ä¿¡å·ï¼‰
- æ¸©åº¦ä¼ æ„Ÿå™¨ï¼šRÂ² 0.35 â†’ 0.59ï¼Œ0.68 â†’ 0.93ï¼ˆä¸­ç­‰æ”¹è¿›ï¼‰
- å‹åŠ›ä¼ æ„Ÿå™¨ï¼šRÂ² 0.08 â†’ 0.47ï¼Œ0.42 â†’ 0.63ï¼ˆæ˜¾è‘—æå‡ï¼‰

<details>
<summary><b>ğŸ“Š ç‚¹å‡»æŸ¥çœ‹å®Œæ•´æ•ˆæœæ¼”ç¤ºå›¾ï¼ˆæ‰€æœ‰ä¿¡å·é¢„æµ‹æ•ˆæœå¯è§†åŒ–ï¼‰</b></summary>

<br>

ä¸‹å›¾å±•ç¤ºäº†ç»è¿‡ Stage1 + Stage2 Boost åï¼Œæ‰€æœ‰ 89 ä¸ªç›®æ ‡ä¿¡å·åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹æ•ˆæœï¼š

![æ‰€æœ‰ä¿¡å·é¢„æµ‹æ•ˆæœæ¼”ç¤º](saved_models/result_demo.webp)

**å›¾ç‰‡è¯´æ˜**ï¼š
- è“è‰²çº¿æ¡ï¼šçœŸå®å€¼ï¼ˆGround Truthï¼‰
- æ©™è‰²çº¿æ¡ï¼šæ¨¡å‹é¢„æµ‹å€¼ï¼ˆPredictionï¼‰
- æ¯ä¸ªå­å›¾ä»£è¡¨ä¸€ä¸ªä¼ æ„Ÿå™¨ä¿¡å·çš„é¢„æµ‹æ•ˆæœ
- å¯ä»¥çœ‹åˆ°å¤§éƒ¨åˆ†ä¿¡å·çš„é¢„æµ‹æ›²çº¿ä¸çœŸå®å€¼é«˜åº¦å»åˆ

</details>

**å®ç”¨è§è§£**ï¼š
- âœ… **å¼ºåŠ²çš„å¼€ç®±å³ç”¨åŸºçº¿**ï¼šStage1 ä½¿ç”¨é»˜è®¤è®¾ç½®è¾¾åˆ° RÂ² = 0.81
- âœ… **æŒ‰éœ€ç²¾ç‚¼**ï¼šStage2 å¢å¼ºä¸ºæŒ‘æˆ˜æ€§ä¿¡å·æä¾›é’ˆå¯¹æ€§æ”¹è¿›
- âœ… **çœŸå®ä¼ æ„Ÿå™¨æ•°æ®**ï¼šåœ¨ç”Ÿäº§è®¾å¤‡æµ‹é‡æ•°æ®ä¸Šå±•ç¤ºæœ‰æ•ˆæ€§
- âœ… **é«˜æ•ˆè®­ç»ƒ**ï¼šä¸¤ä¸ªé˜¶æ®µéƒ½èƒ½åœ¨æ ‡å‡†ç¡¬ä»¶ä¸Šå¿«é€Ÿè®­ç»ƒ

**è®­ç»ƒæ¨¡å‹**ï¼š[Kaggle Models æä¾›](https://www.kaggle.com/models/tianffan/industrial-digital-twin-by-transformer)

**æ¨¡å‹æ–‡ä»¶ä½ç½®**ï¼š
- **Stage1 æ¨¡å‹**ï¼šä¸‰ä¸ªæ–‡ä»¶ï¼ˆ`.pth`ã€`_config.json`ã€`_scaler.pkl`ï¼‰ä½äº `saved_models/` ç›®å½•ä¸‹
- **Stage2 æ¨¡å‹**ï¼šä½äº `saved_models/stage2_boost/` ç›®å½•ä¸‹

**å…³äºåŸºå‡†æµ‹è¯•çš„è¯´æ˜**ï¼š
è¿™äº›ç»“æœä½œä¸ºç‰¹å®šæ•°æ®é›†ä¸Šçš„å‚è€ƒç¤ºä¾‹æä¾›ã€‚æœ¬é¡¹ç›®ä¼˜å…ˆè€ƒè™‘**å®ç”¨æ€§å’Œæ˜“éƒ¨ç½²æ€§**ï¼Œè€Œéç«äº‰æ€§åŸºå‡†åˆ†æ•°ã€‚æ€§èƒ½å°†æ ¹æ®æ‚¨çš„å…·ä½“å·¥ä¸šåº”ç”¨ã€ä¼ æ„Ÿå™¨ç‰¹æ€§å’Œæ•°æ®è´¨é‡è€Œå˜åŒ–ã€‚æˆ‘ä»¬é¼“åŠ±ç”¨æˆ·åœ¨è‡ªå·±çš„åº”ç”¨åœºæ™¯ä¸­è¯„ä¼°æœ¬æ¡†æ¶ã€‚

---

#### ğŸŒ å¤§æ°”ç‰©ç†ä»¿çœŸåŸºå‡†æµ‹è¯•

**æ•°æ®é›†**ï¼šLEAP å¤§æ°”ç‰©ç†ä»¿çœŸæ•°æ®é›†

**æ€§èƒ½ç»“æœ**ï¼š
- **ç¡¬ä»¶**ï¼šå•å¡ NVIDIA A100 GPUï¼ˆGoogle Colabï¼‰
- **ä¿¡å·**ï¼š164 ä¸ªè¾“å‡ºä¿¡å·ï¼ˆä¸åŒ…æ‹¬ ptend_q ç³»åˆ—ï¼‰
- **Stage1 (SST)**ï¼šRÂ² â‰ˆ 0.56
- **Stage2 Boost**ï¼šRÂ² â‰ˆ 0.58
- **è®­ç»ƒ**ï¼šæœªåº”ç”¨æ•°æ®å¢å¼º

**æµ‹è¯• Notebook**ï¼šå‚è§ `notebooks/transformer_boost_Leap_final.ipynb`ï¼ˆä½œè€…æµ‹è¯•æ–‡ä»¶ï¼Œæ³¨é‡Šä¸ºä¸­æ–‡ï¼‰

---

### ğŸ“Œ æ€§èƒ½è¯´æ˜

**å˜å¼‚å› ç´ **ï¼š
ç»“æœå¯èƒ½å› ä»¥ä¸‹å› ç´ è€Œå˜åŒ–ï¼š
- æ•°æ®é›†ç‰¹å¾ï¼ˆä¼ æ„Ÿå™¨ç›¸å…³æ¨¡å¼ã€å™ªå£°æ°´å¹³ã€ä¿¡å·å¤æ‚åº¦ï¼‰
- ç‰©ç†ç³»ç»Ÿå±æ€§ï¼ˆä¼ æ„Ÿå™¨ç©ºé—´å…³ç³»ã€æ—¶é—´åŠ¨æ€ï¼‰
- æ¨¡å‹é…ç½®ï¼ˆæ¶æ„å¤§å°ã€è®­ç»ƒå‚æ•°ï¼‰
- åº”ç”¨é¢†åŸŸï¼ˆåˆ¶é€ ä¸šã€èƒ½æºã€åŒ–å·¥è¿‡ç¨‹ç­‰ï¼‰

**è§‚å¯Ÿåˆ°çš„æœ€ä½³ç»“æœ**ï¼š
- **é«˜åº¦ç›¸å…³çš„ä¼ æ„Ÿå™¨ç³»ç»Ÿ**ï¼šRÂ² > 0.80ï¼ˆå¦‚æ—‹è½¬æœºæ¢°ï¼‰
- **å¤æ‚å¤šç‰©ç†ç³»ç»Ÿ**ï¼šRÂ² 0.55-0.65ï¼ˆå¦‚å¤§æ°”ä»¿çœŸï¼‰

å½“ä¼ æ„Ÿå™¨è¾“å‡ºå…·æœ‰**æ˜ç¡®çš„ç‰©ç†ç›¸äº’ä¾èµ–å…³ç³»å’Œç©ºé—´å…³ç³»**æ—¶ï¼Œè¯¥æ¡†æ¶è¡¨ç°å‡ºç‰¹åˆ«å¼ºçš„æ€§èƒ½ï¼Œè¿™ä¸å…¶æ ¸å¿ƒè®¾è®¡ç†å¿µä¸€è‡´ã€‚

---

### ğŸ¤ æ¬¢è¿ç¤¾åŒºè´¡çŒ®

æˆ‘ä»¬çƒ­çƒˆé¼“åŠ±ç”¨æˆ·åˆ†äº«åŸºå‡†æµ‹è¯•ç»“æœï¼å¦‚æœæ‚¨å·²å°†æ­¤æ¡†æ¶åº”ç”¨äºæ‚¨çš„é¢†åŸŸï¼Œè¯·è´¡çŒ®ï¼š
- æ‚¨å·¥ä¸šåº”ç”¨ä¸­çš„**è„±æ•æ•°æ®é›†**
- **æ€§èƒ½æŒ‡æ ‡**ï¼ˆRÂ²ã€MAEã€RMSE ç­‰ï¼‰å’Œå¯è§†åŒ–
- **åº”ç”¨æ¡ˆä¾‹æè¿°**å’Œé¢†åŸŸè§è§£

æ‚¨çš„è´¡çŒ®æœ‰åŠ©äºå»ºç«‹å¯¹æ¡†æ¶åœ¨ä¸åŒå·¥ä¸šåœºæ™¯ä¸‹èƒ½åŠ›çš„ç†è§£ã€‚è¯·å¼€å¯ [issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues) æˆ–æäº¤ pull requestï¼

## ğŸ¤ è´¡çŒ®

æ„Ÿè°¢æ‚¨å¯¹æœ¬é¡¹ç›®çš„å…³æ³¨ï¼æˆ‘ä»¬éå¸¸é‡è§†ç¤¾åŒºçš„å‚ä¸å’Œåé¦ˆã€‚

**æ”¯æŒæœ¬é¡¹ç›®çš„æ–¹å¼**ï¼š
- â­ **ç»™æˆ‘ä»¬ä¸€ä¸ª starï¼** è¿™æœ‰åŠ©äºæ›´å¤šäººå‘ç°è¿™é¡¹å·¥ä½œï¼Œå¹¶æ¿€åŠ±é¡¹ç›®æŒç»­å‘å±•
- ğŸ› **Bug æŠ¥å‘Šæˆ–å»ºè®®ï¼Ÿ** æ¬¢è¿å¼€å¯ [issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues)
- ğŸ’¬ **æƒ³æ³•æˆ–é—®é¢˜ï¼Ÿ** æ¬¢è¿åœ¨ issue æˆ–è¯„è®ºä¸­è®¨è®º
- ğŸ“Š **æ€§èƒ½ç»“æœï¼Ÿ** åˆ†äº«æ‚¨çš„è„±æ•æ•°æ®å’Œç»“æœ - è¿™äº›ç‰¹åˆ«æœ‰ä»·å€¼ï¼

**å½“å‰çŠ¶æ€**ï¼šç”±äºæ—¶é—´é™åˆ¶ï¼Œä½œè€…å¯èƒ½æ— æ³•ç«‹å³å®¡æŸ¥å’Œåˆå¹¶å¤–éƒ¨çš„ Pull Requestã€‚è¡·å¿ƒæ„Ÿè°¢æ‚¨çš„ç†è§£ã€‚

**å¯¹äºé‡å¤§æ›´æ”¹**ï¼šæ³è¯·æ‚¨å…ˆå¼€å¯ issue è®¨è®ºæ‚¨çš„æè®®ï¼Œç„¶åå†æŠ•å…¥å¤§é‡ç²¾åŠ›ã€‚

â±ï¸ **å›å¤æ—¶é—´**ï¼šä½œè€…ä¼šåœ¨æ—¶é—´å…è®¸çš„æƒ…å†µä¸‹å›å¤ã€‚éå¸¸æ„Ÿè°¢æ‚¨çš„è€å¿ƒã€‚

éå¸¸æ„Ÿè°¢æ‚¨çš„ç†è§£ã€è€å¿ƒå’Œè´¡çŒ®ï¼ğŸ™

### å¼€å‘è®¾ç½®

```bash
# å…‹éš†ä»“åº“
git clone https://github.com/FTF1990/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# ä»¥å¼€å‘æ¨¡å¼å®‰è£…
pip install -e .

# è¿è¡Œæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
python -m pytest tests/
```

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®æ ¹æ® MIT è®¸å¯è¯æˆæƒ - è¯¦æƒ…è¯·å‚é˜… [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- Transformer æ¶æ„åŸºäº "Attention Is All You Need"ï¼ˆVaswani et al., 2017ï¼‰
- çµæ„Ÿæ¥è‡ªå·¥ä¸šè‡ªåŠ¨åŒ–ä¸­çš„æ•°å­—å­ªç”Ÿåº”ç”¨
- ä½¿ç”¨ PyTorchã€Gradio å’Œå‡ºè‰²çš„å¼€æºç¤¾åŒºæ„å»º

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ã€è®®é¢˜æˆ–åˆä½œï¼š
- **GitHub Issues**ï¼š[åˆ›å»º issue](https://github.com/FTF1990/Industrial-digital-twin-by-transformer/issues)
- **ç”µå­é‚®ä»¶**ï¼šshvichenko11@gmail.com

## ğŸ”— å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨æ­¤å·¥ä½œï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@software{industrial_digital_twin_transformer,
  author = {FTF1990},
  title = {Industrial Digital Twin by Transformer},
  year = {2025},
  url = {https://github.com/FTF1990/Industrial-digital-twin-by-transformer}
}
```

## ğŸ—ºï¸ è·¯çº¿å›¾

### v1.0ï¼ˆå½“å‰ï¼‰âœ…
- [x] Stage2 æå‡è®­ç»ƒç³»ç»Ÿ
- [x] æ™ºèƒ½ RÂ² é˜ˆå€¼é€‰æ‹©
- [x] é›†æˆæ¨¡å‹ç”Ÿæˆ
- [x] æ¨ç†å¯¹æ¯”å·¥å…·
- [x] å¢å¼ºå‹ Gradio ç•Œé¢

### v2.0ï¼ˆå³å°†æ¨å‡ºï¼‰ğŸš€

#### **Stage3 æ—¶åºéœ‡è¡å¢å¼ºç³»ç»Ÿ** ğŸ•
ä¸‹ä¸€ä»£æ¼”è¿›ç›®æ ‡ï¼šæ—¶åºéœ‡è¡ä¿¡å·é‡æ„

- **Stage3 æ—¶åºéœ‡è¡ç‰¹å¾æå–**ï¼š
  - é’ˆå¯¹å…·æœ‰æ—¶åºéœ‡è¡ç‰¹æ€§çš„ä¿¡å·ï¼ˆé«˜é¢‘è„‰åŠ¨ã€æŒ¯åŠ¨ç­‰ï¼‰
  - å½“å‰çš„ç©ºé—´åºåˆ— Transformer å¯¹æ—¶åºé«˜é¢‘éœ‡è¡ä¿¡å·åªèƒ½æå–å‡å€¼ç‰¹å¾ï¼Œæ— æ³•è¿˜åŸæ—¶åºéœ‡è¡ç‰¹å¾
  - é‡‡ç”¨æ—¶åº ML æ¨¡å‹æˆ–æ—¶åº Transformer è¿›è¡Œçº¯æ—¶åºç‰¹å¾æå–
  - å¢å¼ºå¹¶è¿˜åŸä¿¡å·æœ¬èº«å›ºæœ‰çš„æ—¶åºéœ‡è¡ç‰¹å¾

- **æœ€ç»ˆæ®‹å·®æœªæ¥é¢„æµ‹**ï¼š
  - ç»è¿‡ Stage1 + Stage2 + Stage3 åï¼Œæœ€ç»ˆæ®‹å·®åŸºæœ¬å·²ä¸åŒ…å«ç©ºé—´ç‰¹å¾
  - å¯å¯¹æœ€ç»ˆæ®‹å·®è¿›è¡Œçº¯æ—¶åºé¢„æµ‹ï¼Œå®ç°æœªæ¥æ—¶é—´æ­¥é¢„æµ‹
  - é€‚ç”¨äºéœ€è¦å‰å‘é¢„æµ‹èƒ½åŠ›çš„åº”ç”¨åœºæ™¯

- **ä¿¡å·å…³è”æ©ç ç¼–è¾‘åŠŸèƒ½**ï¼ˆè®¡åˆ’æ¨å‡ºï¼‰ï¼š
  - æœ€å¤§é™åº¦åˆ©ç”¨ Transformer çš„çµæ´»æ€§ï¼Œç¼–è¾‘è¾“å…¥è¾“å‡ºä¿¡å·å…³è”æ©ç 
  - è¿ç”¨çœŸå®å·¥ç¨‹ç»éªŒå¯¹ä¸ç›´æ¥å…³è”çš„è¦ç´ ä¹‹é—´æ–½åŠ æ©ç å±è”½
  - æ›´å¥½åœ°è¿˜åŸçœŸå®ç³»ç»Ÿè¡Œä¸ºï¼Œèå…¥é¢†åŸŸä¸“å®¶çŸ¥è¯†
  - é€šè¿‡ä¸“å®¶å¼•å¯¼çš„ç‰¹å¾å…³ç³»æé«˜æ¨¡å‹å‡†ç¡®æ€§

- **å®Œæ•´çš„ç©ºé—´-æ—¶é—´åˆ†è§£æ¶æ„**ï¼š
  - **Stage1 (SST)**ï¼šç©ºé—´ä¼ æ„Ÿå™¨å…³ç³»å’Œè·¨ä¼ æ„Ÿå™¨ä¾èµ–æ€§
  - **Stage2 (Boost)**ï¼šç©ºé—´æ®‹å·®ä¿®æ­£å’Œæ¬¡çº§ç©ºé—´æ¨¡å¼
  - **Stage3 (Temporal)**ï¼šçº¯æ—¶åºéœ‡è¡ç‰¹å¾å’Œæ—¶é—´åºåˆ—åŠ¨æ€
  - **æœ€ç»ˆç›®æ ‡**ï¼šå°†ç©ºé—´å’Œæ—¶é—´ç‰¹å¾å®Œå…¨å‰¥ç¦»å¹¶åˆ†å±‚é¢„æµ‹ï¼Œé™¤ä¸å¯é¢„æµ‹çš„å™ªéŸ³ç‰¹å¾å¤–ï¼Œæ•æ‰æ‰€æœ‰å¯é¢„æµ‹æ¨¡å¼ï¼Œå®ç°åœºæ™¯æ³›ç”¨åŒ–çš„æ•°å­—å­ªç”Ÿ

- **åˆ†å±‚ç‰¹å¾æå–å“²å­¦**ï¼š
  - ç¬¬ä¸€å±‚ï¼šä¸»è¦ç©ºé—´ä¼ æ„Ÿå™¨ç›¸å…³æ€§ï¼ˆSSTï¼‰
  - ç¬¬äºŒå±‚ï¼šæ®‹å·®ç©ºé—´æ¨¡å¼ï¼ˆStage2 æå‡ï¼‰
  - ç¬¬ä¸‰å±‚ï¼šæ—¶åºéœ‡è¡ç‰¹å¾ï¼ˆStage3 æ—¶åºï¼‰
  - æœ€ç»ˆæ®‹å·®ï¼šä¸å¯çº¦éšæœºå™ªå£° + å¯é€‰çš„æœªæ¥é¢„æµ‹

æ­¤è®¾è®¡æ—¨åœ¨é€šè¿‡ç³»ç»Ÿæ€§åœ°åˆ†è§£å’Œæ•è·ä¸åŒé¢†åŸŸçš„æ‰€æœ‰å¯é¢„æµ‹ç‰¹å¾ï¼Œå®ç°**é€šç”¨æ•°å­—å­ªç”Ÿå»ºæ¨¡**ã€‚
---

**ä¸ºå·¥ä¸š AI ç¤¾åŒºç²¾å¿ƒæ‰“é€  â¤ï¸**
