# Industrial Digital Twin by Transformer

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)

> **An innovative Transformer-based framework for industrial digital twin modeling using sequential sensor outputs from complex systems.**

This project introduces novel Transformer architectures specifically designed for predicting sensor outputs in industrial digital twin applications. Unlike traditional approaches, our models leverage the **sequential nature of multi-sensor systems** in complex industrial environments to achieve superior prediction accuracy.

## ğŸŒŸ Key Innovation

**Sequential Sensor Prediction using Transformers**: This is the first framework to apply Transformer architecture specifically to the problem of predicting sequential sensor outputs in industrial digital twins. The model treats multiple sensors as a sequence, capturing both spatial relationships between sensors and temporal dependencies in their measurements.

### Why This Matters

In complex industrial systems (manufacturing plants, chemical processes, power generation, etc.), sensors don't operate in isolation. Their outputs are:
- **Spatially correlated**: Physical proximity and process flow create dependencies
- **Temporally dependent**: Historical measurements influence current and future readings
- **Hierarchically structured**: Some sensors measure boundary conditions while others measure internal states

Traditional machine learning approaches treat sensors independently or use simple time-series models. Our Transformer-based approach **captures the full complexity of sensor interrelationships**.

## ğŸš€ Features

### Two Model Architectures

#### **StaticSensorTransformer (SST)**
- **Purpose**: Maps boundary condition sensors to target sensor predictions
- **Architecture**: Transformer encoder with positional encoding for sensor locations
- **Use Case**: Systems with stable relationships between sensors
- **Advantages**:
  - Fast training and inference
  - Lower computational requirements
  - Excellent for static or quasi-static systems
- **Formerly**: V1 or CompactSensorTransformer

#### **HybridSensorTransformer (HST)**
- **Purpose**: Combines temporal context analysis with static sensor mapping
- **Architecture**: Dual-branch Transformer with temporal and static encoders
- **Use Case**: Systems with time-dependent sensor behaviors
- **Advantages**:
  - Captures both instantaneous and historical dependencies
  - Handles sensors with different temporal characteristics
  - Superior performance for dynamic systems
- **Formerly**: V4 or HybridTemporalTransformer

### Additional Features

- âœ… **Modular Design**: Easy to extend and customize
- âœ… **Comprehensive Training Pipeline**: Built-in data preprocessing, training, and evaluation
- âœ… **Interactive Gradio Interface**: User-friendly web interface for training and inference
- âœ… **Jupyter Notebooks**: Complete tutorials and examples
- âœ… **Production Ready**: Exportable models for deployment
- âœ… **Extensive Documentation**: Clear API documentation and usage examples

## ğŸ“Š Use Cases

This framework is ideal for:

- **Manufacturing Digital Twins**: Predict equipment states from sensor arrays
- **Chemical Process Monitoring**: Model complex sensor interactions in reactors
- **Power Plant Optimization**: Forecast turbine and generator conditions
- **HVAC Systems**: Predict temperature and pressure distributions
- **Predictive Maintenance**: Early detection of anomalies from sensor patterns
- **Quality Control**: Predict product quality from process sensors

## ğŸ—ï¸ Architecture Overview

```
Industrial System (Physical)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Boundary Condition Sensors         â”‚
â”‚  (Temperature, Pressure, Flow, etc.)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SST (StaticSensorTransformer)     â”‚
â”‚   - Sensor Embedding Layer           â”‚
â”‚   - Positional Encoding              â”‚
â”‚   - Multi-Head Attention             â”‚
â”‚   - Feed Forward Networks            â”‚
â”‚   - Global Pooling                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
        OR
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HST (HybridSensorTransformer)     â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚  Temporal Branch               â”‚ â”‚
â”‚   â”‚  - Context Window Analysis     â”‚ â”‚
â”‚   â”‚  - Temporal Attention          â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚  Static Branch                 â”‚ â”‚
â”‚   â”‚  - Instant Sensor Mapping      â”‚ â”‚
â”‚   â”‚  - Spatial Attention           â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚  Fusion Layer                  â”‚ â”‚
â”‚   â”‚  - Combines Both Branches      â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Target Sensor Predictions          â”‚
â”‚   (Internal States, Quality Metrics) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Installation

### Quick Start with Google Colab

```bash
# Clone the repository
!git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
%cd Industrial-digital-twin-by-transformer

# Install dependencies
!pip install -r requirements.txt
```

### Local Installation

```bash
# Clone the repository
git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“š Quick Start

### 1. Prepare Your Data

Place your CSV sensor data file in the `data/raw/` folder. Your CSV should have:
- Each row represents a timestep
- Each column represents a sensor measurement
- (Optional) First column can be a timestamp

Example CSV structure:
```csv
timestamp,sensor_1,sensor_2,sensor_3,...,sensor_n
2025-01-01 00:00:00,23.5,101.3,45.2,...,78.9
2025-01-01 00:00:01,23.6,101.4,45.1,...,79.0
...
```

### 2. Train Using Jupyter Notebook

Open `notebooks/train_and_inference.ipynb` and follow the step-by-step tutorial:

```python
from models.static_transformer import StaticSensorTransformer
from src.data_loader import SensorDataLoader
from src.trainer import ModelTrainer

# Load data
data_loader = SensorDataLoader(data_path='data/raw/your_data.csv')

# Configure signals
boundary_signals = ['sensor_1', 'sensor_2', 'sensor_3']  # Inputs
target_signals = ['sensor_4', 'sensor_5']  # Outputs to predict

# Prepare data
data_splits = data_loader.prepare_data(boundary_signals, target_signals)

# Create and train model
model = StaticSensorTransformer(
    num_boundary_sensors=len(boundary_signals),
    num_target_sensors=len(target_signals)
)

trainer = ModelTrainer(model, device='cuda')
history = trainer.train(train_loader, val_loader)
```

### 3. Use Gradio Interface (Interactive)

Launch the interactive web interface for easy experimentation:

```bash
python gradio_app.py
```

Or run the Gradio notebook:
```bash
jupyter notebook notebooks/gradio_interface.ipynb
```

The interface provides:
- ğŸ“Š **Data Loading**: Upload and visualize your sensor data
- ğŸ¯ **Model Training**: Configure and train SST/HST models with real-time progress
- ğŸ”® **Inference**: Make predictions and visualize results
- ğŸ’¾ **Export**: Save trained models and configurations

## ğŸ“– Documentation

### Project Structure

```
Industrial-digital-twin-by-transformer/
â”œâ”€â”€ models/                      # Model implementations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ static_transformer.py    # SST (StaticSensorTransformer)
â”‚   â”œâ”€â”€ hybrid_transformer.py    # HST (HybridSensorTransformer)
â”‚   â”œâ”€â”€ utils.py                # Utility functions
â”‚   â””â”€â”€ saved/                  # Saved model checkpoints
â”œâ”€â”€ src/                        # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py         # Data loading and preprocessing
â”‚   â”œâ”€â”€ trainer.py             # Training pipeline
â”‚   â””â”€â”€ inference.py           # Inference engine
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”‚   â”œâ”€â”€ train_and_inference.ipynb  # Main tutorial
â”‚   â””â”€â”€ gradio_interface.ipynb     # Gradio interface
â”œâ”€â”€ data/                      # Data folder
â”‚   â”œâ”€â”€ raw/                   # Place your CSV files here
â”‚   â””â”€â”€ README.md             # Data format guide
â”œâ”€â”€ examples/                  # Example scripts
â”‚   â””â”€â”€ quick_start.py        # Quick start example
â”œâ”€â”€ configs/                   # Configuration files
â”œâ”€â”€ gradio_app.py             # Gradio application
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ setup.py                  # Package setup
â”œâ”€â”€ LICENSE                   # MIT License
â””â”€â”€ README.md                # This file
```

### Model APIs

#### StaticSensorTransformer (SST)

```python
from models.static_transformer import StaticSensorTransformer

model = StaticSensorTransformer(
    num_boundary_sensors=10,    # Number of input sensors
    num_target_sensors=5,       # Number of output sensors
    d_model=128,                # Model dimension
    nhead=8,                    # Number of attention heads
    num_layers=3,               # Number of transformer layers
    dropout=0.1                 # Dropout rate
)

# Forward pass
predictions = model(boundary_conditions)  # Shape: (batch_size, num_target_sensors)
```

#### HybridSensorTransformer (HST)

```python
from models.hybrid_transformer import HybridSensorTransformer

model = HybridSensorTransformer(
    num_boundary_sensors=10,    # Number of input sensors
    num_target_sensors=5,       # Number of output sensors
    d_model=64,                 # Model dimension
    nhead=4,                    # Number of attention heads
    num_layers=2,               # Number of transformer layers
    dropout=0.1,                # Dropout rate
    use_temporal=True,          # Enable temporal branch
    context_window=5            # Context window size (Â±5 timesteps)
)

# Forward pass with temporal context
predictions = model(boundary_conditions)  # Shape: (batch_size, num_target_sensors)
```

## ğŸ¯ Performance

### Benchmark Results (Example)

On a typical industrial sensor dataset with 50 boundary sensors and 20 target sensors:

| Model | Average RÂ² | Average RMSE | Training Time | Inference Time |
|-------|-----------|--------------|---------------|----------------|
| **SST (Static)** | 0.92 | 2.34 | ~15 min | 0.5 ms/sample |
| **HST (Hybrid)** | 0.96 | 1.67 | ~25 min | 1.2 ms/sample |

*Note: Results vary depending on dataset characteristics and hardware.*

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Development Setup

```bash
# Clone repository
git clone https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer.git
cd Industrial-digital-twin-by-transformer

# Install in development mode
pip install -e .

# Run tests (if available)
python -m pytest tests/
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Transformer architecture based on "Attention Is All You Need" (Vaswani et al., 2017)
- Inspired by digital twin applications in industrial automation
- Built with PyTorch, Gradio, and the amazing open-source community

## ğŸ“ Contact

For questions, issues, or collaborations:
- **GitHub Issues**: [Create an issue](https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer/issues)
- **Email**: your.email@example.com

## ğŸ”— Citation

If you use this work in your research, please cite:

```bibtex
@software{industrial_digital_twin_transformer,
  author = {Your Name},
  title = {Industrial Digital Twin by Transformer},
  year = {2025},
  url = {https://github.com/YOUR_USERNAME/Industrial-digital-twin-by-transformer}
}
```

## ğŸ—ºï¸ Roadmap

- [ ] Add LSTM baseline for comparison
- [ ] Implement attention visualization
- [ ] Add more preprocessing options
- [ ] Support for real-time streaming data
- [ ] Docker containerization
- [ ] REST API for model serving
- [ ] Additional example datasets
- [ ] Hyperparameter optimization guide

---

**Made with â¤ï¸ for the Industrial AI Community**
