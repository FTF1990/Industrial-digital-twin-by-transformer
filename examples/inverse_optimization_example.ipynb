{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse Control Optimization Example\n",
    "\n",
    "This notebook demonstrates the complete workflow for inverse optimization using trained digital twin models.\n",
    "\n",
    "## Table of Contents\n",
    "1. Setup and Model Loading\n",
    "2. Single-Objective Optimization\n",
    "3. Multi-Objective Optimization (Pareto Frontier)\n",
    "4. Kalman Filter Real-Time Correction\n",
    "\n",
    "## Prerequisites\n",
    "- A trained Stage1 SST model\n",
    "- Test data for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "from models.static_transformer import StaticSensorTransformer\n",
    "from optimization import (\n",
    "    InverseOptimizer,\n",
    "    MultiObjectiveOptimizer,\n",
    "    KalmanCorrector,\n",
    "    ConstraintManager,\n",
    "    InputConstraint,\n",
    "    OptimizationConfig,\n",
    "    MultiObjectiveConfig,\n",
    "    KalmanConfig\n",
    ")\n",
    "\n",
    "# Check CUDA availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model path\n",
    "model_path = '../saved_models/stage1_model.pth'\n",
    "config_path = model_path.replace('.pth', '_config.json')\n",
    "scaler_path = model_path.replace('.pth', '_scaler.pkl')\n",
    "\n",
    "# Load configuration\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(\"Model Configuration:\")\n",
    "print(f\"  Boundary signals: {len(config['boundary_signals'])}\")\n",
    "print(f\"  Target signals: {len(config['target_signals'])}\")\n",
    "print(f\"  Model dimension: {config.get('d_model', 128)}\")\n",
    "\n",
    "# Load scalers\n",
    "with open(scaler_path, 'rb') as f:\n",
    "    scalers = pickle.load(f)\n",
    "\n",
    "scaler_X = scalers['scaler_X']\n",
    "scaler_y = scalers['scaler_y']\n",
    "\n",
    "# Create and load model\n",
    "model = StaticSensorTransformer(\n",
    "    num_boundary_sensors=len(config['boundary_signals']),\n",
    "    num_target_sensors=len(config['target_signals']),\n",
    "    d_model=config.get('d_model', 128),\n",
    "    nhead=config.get('nhead', 8),\n",
    "    num_layers=config.get('num_layers', 3)\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "\n",
    "# Store signal names\n",
    "boundary_signals = config['boundary_signals']\n",
    "target_signals = config['target_signals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = '../data/data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a baseline sample\n",
    "baseline_idx = 0\n",
    "baseline_inputs = df.iloc[baseline_idx][boundary_signals].values\n",
    "baseline_targets = df.iloc[baseline_idx][target_signals].values\n",
    "\n",
    "# Make prediction\n",
    "X_scaled = scaler_X.transform(baseline_inputs.reshape(1, -1))\n",
    "X_tensor = torch.from_numpy(X_scaled).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_scaled = model(X_tensor)\n",
    "    baseline_predictions = scaler_y.inverse_transform(y_pred_scaled.cpu().numpy())[0]\n",
    "\n",
    "print(\"Baseline Predictions:\")\n",
    "for i, signal in enumerate(target_signals[:5]):  # Show first 5\n",
    "    print(f\"  {signal}: {baseline_predictions[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Single-Objective Optimization\n",
    "\n",
    "**Scenario:** Reduce a specific target signal by 10% by optimizing selected input parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimization Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target signal to optimize (e.g., first target signal)\n",
    "target_signal_name = target_signals[0]\n",
    "target_signal_idx = 0\n",
    "\n",
    "# Define target: reduce by 10%\n",
    "target_bias = -0.10  # -10%\n",
    "\n",
    "targets = {\n",
    "    target_signal_idx: {\n",
    "        'bias': target_bias,\n",
    "        'weight': 1.0\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Optimization Target:\")\n",
    "print(f\"  Signal: {target_signal_name}\")\n",
    "print(f\"  Current value: {baseline_predictions[target_signal_idx]:.4f}\")\n",
    "print(f\"  Target value: {baseline_predictions[target_signal_idx] * (1 + target_bias):.4f}\")\n",
    "print(f\"  Change: {target_bias*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Variable Inputs and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 3 inputs to optimize (e.g., first 3 boundary signals)\n",
    "optimizable_signal_names = boundary_signals[:3]\n",
    "optimizable_indices = [0, 1, 2]\n",
    "\n",
    "# Create constraints\n",
    "constraints_list = []\n",
    "\n",
    "for i, signal_name in enumerate(boundary_signals):\n",
    "    baseline_value = baseline_inputs[i]\n",
    "    \n",
    "    if i in optimizable_indices:\n",
    "        # Optimizable: allow Â±50% range, Â±20% change rate\n",
    "        constraints_list.append(InputConstraint(\n",
    "            name=signal_name,\n",
    "            min_value=baseline_value * 0.5,\n",
    "            max_value=baseline_value * 1.5,\n",
    "            baseline_value=baseline_value,\n",
    "            max_change_rate=0.20,  # Â±20%\n",
    "            is_fixed=False\n",
    "        ))\n",
    "    else:\n",
    "        # Fixed: keep at baseline value\n",
    "        constraints_list.append(InputConstraint(\n",
    "            name=signal_name,\n",
    "            min_value=baseline_value,\n",
    "            max_value=baseline_value,\n",
    "            baseline_value=baseline_value,\n",
    "            is_fixed=True\n",
    "        ))\n",
    "\n",
    "constraint_manager = ConstraintManager(constraints_list)\n",
    "\n",
    "print(constraint_manager.get_constraint_summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inverse Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer\n",
    "optimizer = InverseOptimizer(\n",
    "    model=model,\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "opt_config = OptimizationConfig(\n",
    "    learning_rate=0.01,\n",
    "    max_epochs=500,\n",
    "    optimizer_type='adam',\n",
    "    patience=50,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run optimization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Running Inverse Optimization...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = optimizer.optimize(\n",
    "    targets=targets,\n",
    "    constraint_manager=constraint_manager,\n",
    "    initial_inputs=baseline_inputs,\n",
    "    config=opt_config\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Optimization Completed!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\nðŸ“Š Optimization Results:\")\n",
    "print(f\"  Converged: {result['converged']}\")\n",
    "print(f\"  Epochs: {result['num_epochs']}\")\n",
    "print(f\"  Final loss: {result['final_loss']:.6f}\")\n",
    "print(f\"  Elapsed time: {result['elapsed_time']:.2f}s\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Target Achievement:\")\n",
    "current_val = baseline_predictions[target_signal_idx]\n",
    "optimized_val = result['predictions'][target_signal_idx]\n",
    "target_val = current_val * (1 + target_bias)\n",
    "\n",
    "print(f\"  Target signal: {target_signal_name}\")\n",
    "print(f\"  Current: {current_val:.4f}\")\n",
    "print(f\"  Optimized: {optimized_val:.4f}\")\n",
    "print(f\"  Target: {target_val:.4f}\")\n",
    "print(f\"  Achievement: {(optimized_val - current_val) / (target_val - current_val) * 100:.1f}%\")\n",
    "\n",
    "print(\"\\nðŸ”§ Input Changes:\")\n",
    "for i in optimizable_indices:\n",
    "    signal_name = boundary_signals[i]\n",
    "    baseline_val = baseline_inputs[i]\n",
    "    optimized_val = result['optimized_inputs'][i]\n",
    "    change_pct = (optimized_val - baseline_val) / baseline_val * 100\n",
    "    \n",
    "    print(f\"  {signal_name}:\")\n",
    "    print(f\"    {baseline_val:.4f} â†’ {optimized_val:.4f} ({change_pct:+.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss convergence\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(result['loss_history'], linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Convergence')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot input evolution for optimizable inputs\n",
    "for i in optimizable_indices:\n",
    "    plt.plot(result['input_history'][:, i], label=boundary_signals[i], linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Input Value')\n",
    "plt.title('Input Evolution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi-Objective Optimization (Pareto Frontier)\n",
    "\n",
    "**Scenario:** Optimize two conflicting objectives and explore trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two objectives\n",
    "# Objective 1: Reduce target signal 0 by 10%\n",
    "# Objective 2: Increase target signal 1 by 5%\n",
    "\n",
    "obj1_idx = 0\n",
    "obj1_bias = -0.10  # -10%\n",
    "\n",
    "obj2_idx = 1 if len(target_signals) > 1 else 0\n",
    "obj2_bias = 0.05  # +5%\n",
    "\n",
    "objectives = [\n",
    "    {'signal_idx': obj1_idx, 'bias': obj1_bias},\n",
    "    {'signal_idx': obj2_idx, 'bias': obj2_bias}\n",
    "]\n",
    "\n",
    "print(\"Multi-Objective Configuration:\")\n",
    "print(f\"  Objective 1: {target_signals[obj1_idx]} ({obj1_bias*100:+.0f}%)\")\n",
    "print(f\"  Objective 2: {target_signals[obj2_idx]} ({obj2_bias*100:+.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-objective optimizer\n",
    "mo_optimizer = MultiObjectiveOptimizer(\n",
    "    model=model,\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "mo_config = MultiObjectiveConfig(\n",
    "    n_pareto_points=20,\n",
    "    base_config=OptimizationConfig(\n",
    "        max_epochs=300,\n",
    "        verbose=False  # Disable verbose for batch optimization\n",
    "    )\n",
    ")\n",
    "\n",
    "# Generate Pareto frontier\n",
    "print(\"\\nGenerating Pareto frontier...\")\n",
    "pareto_results = mo_optimizer.generate_pareto_frontier(\n",
    "    objectives=objectives,\n",
    "    constraint_manager=constraint_manager,\n",
    "    initial_inputs=baseline_inputs,\n",
    "    config=mo_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Pareto frontier\n",
    "fig = mo_optimizer.plot_pareto_frontier(\n",
    "    pareto_results,\n",
    "    objective_names=[target_signals[obj1_idx], target_signals[obj2_idx]],\n",
    "    use_plotly=False  # Use matplotlib for notebook compatibility\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Pareto solutions table\n",
    "solutions_data = []\n",
    "for i, point in enumerate(pareto_results['pareto_points'][:10]):  # Show first 10\n",
    "    solutions_data.append({\n",
    "        'ID': i,\n",
    "        'Weight_1': point['weight_1'],\n",
    "        'Weight_2': point['weight_2'],\n",
    "        f\"{target_signals[obj1_idx]}\": point['objective_1'],\n",
    "        f\"{target_signals[obj2_idx]}\": point['objective_2'],\n",
    "        'Converged': point['converged']\n",
    "    })\n",
    "\n",
    "solutions_df = pd.DataFrame(solutions_data)\n",
    "print(\"\\nPareto Solutions (first 10):\")\n",
    "solutions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select and Analyze a Pareto Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select solution at index 10 (middle of the frontier)\n",
    "selected_idx = 10\n",
    "selected_solution = mo_optimizer.select_solution(pareto_results, selected_idx)\n",
    "\n",
    "print(f\"Selected Pareto Solution #{selected_idx}:\")\n",
    "print(f\"  Weights: [{selected_solution['weight_1']:.2f}, {selected_solution['weight_2']:.2f}]\")\n",
    "print(f\"  {target_signals[obj1_idx]}: {selected_solution['objective_1']:.4f}\")\n",
    "print(f\"  {target_signals[obj2_idx]}: {selected_solution['objective_2']:.4f}\")\n",
    "\n",
    "print(\"\\n  Optimized Inputs:\")\n",
    "for i in optimizable_indices:\n",
    "    print(f\"    {boundary_signals[i]}: {selected_solution['inputs'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kalman Filter Real-Time Correction\n",
    "\n",
    "**Scenario:** Use Kalman filtering to correct optimized control strategy based on simulated sensor feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the single-objective optimization result from Section 2\n",
    "optimized_inputs = result['optimized_inputs']\n",
    "optimized_predictions = result['predictions']\n",
    "\n",
    "# Create Kalman corrector\n",
    "kf = KalmanCorrector(\n",
    "    model=model,\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    optimizable_input_indices=optimizable_indices,\n",
    "    target_output_indices=[target_signal_idx],\n",
    "    fixed_input_values=optimized_inputs,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Kalman Filter Configuration:\")\n",
    "print(f\"  Optimizable inputs: {len(optimizable_indices)}\")\n",
    "print(f\"  Target outputs: 1\")\n",
    "print(f\"  State dimension: {kf.dim_x}\")\n",
    "print(f\"  Measurement dimension: {kf.dim_z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic measurements with noise\n",
    "n_steps = 50\n",
    "measurement_noise_std = 0.1  # 10% noise\n",
    "\n",
    "np.random.seed(42)\n",
    "measurements = []\n",
    "true_value = optimized_predictions[target_signal_idx]\n",
    "\n",
    "for t in range(n_steps):\n",
    "    noise = np.random.normal(0, measurement_noise_std * true_value)\n",
    "    measurements.append([true_value + noise])\n",
    "\n",
    "measurements = np.array(measurements)\n",
    "\n",
    "print(f\"Generated {n_steps} noisy measurements\")\n",
    "print(f\"  True value: {true_value:.4f}\")\n",
    "print(f\"  Noise std: {measurement_noise_std * true_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Kalman simulation\n",
    "initial_inputs_opt = optimized_inputs[optimizable_indices]\n",
    "initial_outputs = np.array([true_value])\n",
    "initial_state = np.concatenate([initial_inputs_opt, initial_outputs])\n",
    "\n",
    "kf_config = KalmanConfig(\n",
    "    process_noise=0.01,\n",
    "    measurement_noise=0.1,\n",
    "    initial_state_covariance=1.0\n",
    ")\n",
    "\n",
    "print(\"Running Kalman filter simulation...\")\n",
    "sim_results = kf.run_simulation(\n",
    "    initial_state=initial_state,\n",
    "    measurements=measurements,\n",
    "    config=kf_config\n",
    ")\n",
    "\n",
    "print(\"âœ… Simulation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correction results\n",
    "uncorrected_predictions = np.tile([true_value], (n_steps, 1))\n",
    "\n",
    "fig = KalmanCorrector.plot_correction_results(\n",
    "    simulation_results=sim_results,\n",
    "    uncorrected_predictions=uncorrected_predictions,\n",
    "    target_names=[target_signal_name],\n",
    "    figsize=(15, 5)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correction metrics\n",
    "metrics_df = kf.compute_correction_metrics(\n",
    "    simulation_results=sim_results,\n",
    "    uncorrected_predictions=uncorrected_predictions\n",
    ")\n",
    "\n",
    "print(\"\\nðŸ“Š Kalman Correction Metrics:\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nâœ… Average RMSE improvement: {metrics_df['RMSE_Improvement_%'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Single-Objective Optimization**: Optimized input parameters to achieve a target output reduction\n",
    "2. **Multi-Objective Optimization**: Generated Pareto frontier to explore trade-offs between conflicting objectives\n",
    "3. **Kalman Filter Correction**: Applied real-time correction to handle measurement noise\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Inverse optimization converges in **seconds** (typically < 2s on GPU)\n",
    "- Gradient-based approach works with **any trained model** without requiring model invertibility\n",
    "- **Constraints** (hard bounds and change rates) are naturally handled through projection\n",
    "- **Multi-objective** optimization provides a spectrum of trade-off solutions\n",
    "- **Kalman filtering** can significantly improve robustness in noisy environments\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Apply to your specific use case with real data\n",
    "- Tune optimization parameters (learning rate, patience, etc.)\n",
    "- Experiment with different constraint configurations\n",
    "- Integrate into production control systems"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
