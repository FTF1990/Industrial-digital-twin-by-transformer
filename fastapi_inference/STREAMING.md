# WebSocket æµå¼æ¨ç†æ–‡æ¡£

FastAPI æ¨ç†æœåŠ¡çš„ WebSocket æµå¼æ¨ç†åŠŸèƒ½å®Œæ•´æ–‡æ¡£ã€‚

## ğŸŒŠ æ¦‚è¿°

æµå¼æ¨ç†é€šè¿‡ WebSocket æä¾›å®æ—¶ã€ä½å»¶è¿Ÿçš„é¢„æµ‹æœåŠ¡ï¼Œé€‚ç”¨äºï¼š
- å®æ—¶ä¼ æ„Ÿå™¨æ•°æ®æµ
- æŒç»­ç›‘æ§ç³»ç»Ÿ
- é«˜é¢‘ç‡é¢„æµ‹åœºæ™¯
- IoT è®¾å¤‡æ•°æ®å¤„ç†

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### Python å®¢æˆ·ç«¯

```python
import asyncio
import websockets
import json

async def stream_inference():
    uri = "ws://localhost:8000/api/v1/inference/stream"
    
    async with websockets.connect(uri) as websocket:
        # 1. å‘é€é…ç½®
        await websocket.send(json.dumps({
            "type": "config",
            "data": {
                "ensemble_name": "Ensemble_your_model_20251215_103000",
                "mode": "single"
            }
        }))
        
        # 2. æ¥æ”¶ç¡®è®¤
        config_ack = json.loads(await websocket.recv())
        print(f"Connected: {config_ack['session_id']}")
        
        # 3. å‘é€æ•°æ®å¹¶è·å–é¢„æµ‹
        await websocket.send(json.dumps({
            "type": "predict",
            "data": {
                "boundary_signals": {
                    "Temperature_boundary_1": 23.5,
                    "Pressure_boundary_1": 101.3,
                    # ... å…¶ä»–è¾¹ç•Œä¿¡å·
                }
            }
        }))
        
        # 4. æ¥æ”¶é¢„æµ‹ç»“æœ
        result = json.loads(await websocket.recv())
        print(f"Prediction: {result['data']['predictions']}")

asyncio.run(stream_inference())
```

---

## ğŸ“¡ WebSocket åè®®

### è¿æ¥ URL

```
ws://localhost:8000/api/v1/inference/stream
```

### æ¶ˆæ¯æ ¼å¼

æ‰€æœ‰æ¶ˆæ¯ä½¿ç”¨ JSON æ ¼å¼ï¼ŒåŒ…å« `type` å’Œ `data` å­—æ®µã€‚

---

## ğŸ“‹ æ¶ˆæ¯ç±»å‹

### 1. é…ç½®æ¶ˆæ¯ (config)

**å®¢æˆ·ç«¯å‘é€**:
```json
{
  "type": "config",
  "data": {
    "ensemble_name": "Ensemble_my_sst_model_20251215_103000",
    "manual_boost_signals": {
      "Temperature_1": true,
      "Pressure_2": false
    },
    "mode": "single",
    "batch_size": 10,
    "include_metadata": true,
    "output_format": "json"
  }
}
```

**æœåŠ¡å™¨å“åº”**:
```json
{
  "type": "config_ack",
  "status": "success",
  "message": "Configuration applied",
  "session_id": "session_abc123",
  "ensemble_info": {
    "ensemble_name": "Ensemble_xxx",
    "num_signals": 20,
    "signals_using_boost": 12
  }
}
```

---

### 2. å•æ¡é¢„æµ‹ (predict)

**å®¢æˆ·ç«¯å‘é€**:
```json
{
  "type": "predict",
  "data": {
    "boundary_signals": {
      "Temperature_boundary_1": 23.5,
      "Pressure_boundary_1": 101.3,
      "Flow_boundary_1": 50.2
    },
    "timestamp": "2025-12-15T10:30:00"
  }
}
```

**æœåŠ¡å™¨å“åº”**:
```json
{
  "type": "prediction",
  "status": "success",
  "data": {
    "predictions": {
      "Temperature_1": 25.3,
      "Pressure_2": 102.1,
      "Flow_3": 55.6
    },
    "signals_used_boost": ["Temperature_1", "Flow_3"],
    "latency_ms": 12.5,
    "timestamp": "2025-12-15T10:30:00"
  }
}
```

---

### 3. æ‰¹é‡é¢„æµ‹ (predict_batch)

**å®¢æˆ·ç«¯å‘é€**:
```json
{
  "type": "predict_batch",
  "data": {
    "batch": [
      {
        "Temperature_boundary_1": 23.5,
        "Pressure_boundary_1": 101.3
      },
      {
        "Temperature_boundary_1": 23.6,
        "Pressure_boundary_1": 101.4
      }
    ],
    "timestamps": ["2025-12-15T10:30:00", "2025-12-15T10:30:01"]
  }
}
```

**æœåŠ¡å™¨å“åº”**:
```json
{
  "type": "prediction_batch",
  "status": "success",
  "data": {
    "predictions": [
      {"Temperature_1": 25.3, "Pressure_2": 102.1},
      {"Temperature_1": 25.4, "Pressure_2": 102.2}
    ],
    "count": 2,
    "latency_ms": 25.8
  }
}
```

---

### 4. å¿ƒè·³æ£€æµ‹ (ping/pong)

**å®¢æˆ·ç«¯å‘é€**:
```json
{
  "type": "ping"
}
```

**æœåŠ¡å™¨å“åº”**:
```json
{
  "type": "pong",
  "timestamp": "2025-12-15T10:30:00"
}
```

---

### 5. é”™è¯¯å“åº” (error)

**æœåŠ¡å™¨å“åº”**:
```json
{
  "type": "error",
  "error_code": "MISSING_SIGNALS",
  "message": "Missing boundary signals: ['Temperature_boundary_1']",
  "details": {
    "missing_signals": ["Temperature_boundary_1"]
  }
}
```

**é”™è¯¯ä»£ç **:
- `INVALID_MESSAGE` - æ¶ˆæ¯æ ¼å¼é”™è¯¯
- `MISSING_ENSEMBLE` - ç¼ºå°‘ ensemble åç§°
- `ENSEMBLE_NOT_FOUND` - Ensemble ä¸å­˜åœ¨
- `MISSING_SIGNALS` - ç¼ºå°‘å¿…éœ€çš„è¾¹ç•Œä¿¡å·
- `EMPTY_BATCH` - æ‰¹é‡æ•°æ®ä¸ºç©º
- `BATCH_TOO_LARGE` - æ‰¹é‡å¤§å°è¶…è¿‡é™åˆ¶
- `PREDICTION_ERROR` - é¢„æµ‹è¿‡ç¨‹é”™è¯¯
- `UNKNOWN_MESSAGE_TYPE` - æœªçŸ¥æ¶ˆæ¯ç±»å‹
- `INVALID_JSON` - JSON è§£æé”™è¯¯
- `INTERNAL_ERROR` - æœåŠ¡å™¨å†…éƒ¨é”™è¯¯

---

## ğŸ”§ HTTP ç«¯ç‚¹

### è·å–ç»Ÿè®¡ä¿¡æ¯

**ç«¯ç‚¹**: `GET /api/v1/inference/stream/stats`

**å“åº”**:
```json
{
  "active_connections": 3,
  "total_predictions": 12543,
  "average_latency_ms": 15.2,
  "connections": [
    {
      "session_id": "session_abc123",
      "ensemble_name": "Ensemble_xxx",
      "connected_at": "2025-12-15T10:00:00",
      "predictions_count": 523,
      "mode": "single"
    }
  ]
}
```

### ä¿å­˜å†å²è®°å½•

**ç«¯ç‚¹**: `POST /api/v1/inference/stream/save`

**è¯·æ±‚**:
```json
{
  "session_id": "session_abc123",
  "output_dir": "fastapi_inference/results/stream",
  "format": "csv"
}
```

**å“åº”**:
```json
{
  "status": "success",
  "message": "History saved successfully",
  "output_path": "fastapi_inference/results/stream/stream_history_session_abc123_20251215_103000.csv",
  "samples_saved": 523
}
```

---

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹ 1: å®æ—¶æ•°æ®æµ

```python
import asyncio
import websockets
import json
import time

async def realtime_stream():
    uri = "ws://localhost:8000/api/v1/inference/stream"
    
    async with websockets.connect(uri) as ws:
        # é…ç½®
        await ws.send(json.dumps({
            "type": "config",
            "data": {
                "ensemble_name": "Ensemble_my_model_20251215_103000",
                "mode": "single"
            }
        }))
        await ws.recv()  # æ¥æ”¶ config_ack
        
        # æŒç»­å‘é€æ•°æ®
        while True:
            # æ¨¡æ‹Ÿä¼ æ„Ÿå™¨è¯»æ•°
            data = {
                "type": "predict",
                "data": {
                    "boundary_signals": {
                        "Temperature_boundary_1": 20 + time.time() % 10,
                        "Pressure_boundary_1": 100 + time.time() % 5,
                        # ...
                    }
                }
            }
            
            await ws.send(json.dumps(data))
            result = json.loads(await ws.recv())
            
            if result['type'] == 'prediction':
                print(f"Latency: {result['data']['latency_ms']:.2f} ms")
            
            await asyncio.sleep(0.05)  # 20 Hz

asyncio.run(realtime_stream())
```

### ç¤ºä¾‹ 2: æ‰¹é‡å¤„ç†

```python
async def batch_processing():
    uri = "ws://localhost:8000/api/v1/inference/stream"
    
    async with websockets.connect(uri) as ws:
        # é…ç½®æ‰¹é‡æ¨¡å¼
        await ws.send(json.dumps({
            "type": "config",
            "data": {
                "ensemble_name": "Ensemble_my_model_20251215_103000",
                "mode": "batch",
                "batch_size": 50
            }
        }))
        await ws.recv()
        
        # å‡†å¤‡æ‰¹é‡æ•°æ®
        batch = []
        for i in range(50):
            batch.append({
                "Temperature_boundary_1": 23.5 + i * 0.1,
                "Pressure_boundary_1": 101.3 + i * 0.05,
                # ...
            })
        
        # å‘é€æ‰¹é‡è¯·æ±‚
        await ws.send(json.dumps({
            "type": "predict_batch",
            "data": {"batch": batch}
        }))
        
        result = json.loads(await ws.recv())
        print(f"Processed {result['data']['count']} samples")
        print(f"Total latency: {result['data']['latency_ms']:.2f} ms")

asyncio.run(batch_processing())
```

### ç¤ºä¾‹ 3: ä½¿ç”¨å®¢æˆ·ç«¯ç±»

å‚è§å®Œæ•´ç¤ºä¾‹ï¼š`fastapi_inference/tests/demo_stream_client.py`

```bash
# è¿è¡Œ Demo
python fastapi_inference/tests/demo_stream_client.py
```

---

## ğŸ“Š æ€§èƒ½ç‰¹æ€§

### å»¶è¿Ÿ

- **å•æ¡æ¨¡å¼**: é€šå¸¸ 10-20msï¼ˆå–å†³äºæ¨¡å‹å¤§å°å’Œç¡¬ä»¶ï¼‰
- **æ‰¹é‡æ¨¡å¼**: æ›´é«˜ååé‡ï¼Œä½†å•æ ·æœ¬å»¶è¿Ÿç¨é«˜
- **WebSocket å¼€é”€**: < 1ms

### ååé‡

- **å•æ¡æ¨¡å¼**: ~50-100 predictions/secï¼ˆå–å†³äºæ¨¡å‹ï¼‰
- **æ‰¹é‡æ¨¡å¼**: ~500-1000 predictions/secï¼ˆæ‰¹é‡å¤§å° 50-100ï¼‰
- **å¤šè¿æ¥**: æ”¯æŒå¤šä¸ªå¹¶å‘ WebSocket è¿æ¥

### å»ºè®®

- **é«˜é¢‘ä½å»¶è¿Ÿ**: ä½¿ç”¨å•æ¡æ¨¡å¼
- **é«˜ååé‡**: ä½¿ç”¨æ‰¹é‡æ¨¡å¼ï¼Œæ‰¹é‡å¤§å° 20-50
- **æŒç»­ç›‘æ§**: å®šæœŸå‘é€ ping æ£€æŸ¥è¿æ¥

---

## ğŸ”’ å®‰å…¨è€ƒè™‘

### è¿æ¥é™åˆ¶

- é»˜è®¤æ— é™åˆ¶ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®é…ç½®
- å¯é€šè¿‡ä¸­é—´ä»¶æ·»åŠ é€Ÿç‡é™åˆ¶

### æ•°æ®éªŒè¯

- æ‰€æœ‰è¾“å…¥æ•°æ®ä¸¥æ ¼éªŒè¯
- ä¿¡å·åç§°å’Œæ•°é‡æ£€æŸ¥
- æ‰¹é‡å¤§å°é™åˆ¶

### è¶…æ—¶å¤„ç†

- é•¿æ—¶é—´æ— æ´»åŠ¨è¿æ¥ä¼šè¢«è‡ªåŠ¨æ–­å¼€
- å»ºè®®å®šæœŸå‘é€ ping ä¿æŒè¿æ¥

---

## ğŸ› æ•…éšœæ’é™¤

### è¿æ¥å¤±è´¥

```
WebSocketException: Connection refused
```

**è§£å†³**:
1. ç¡®è®¤æœåŠ¡å™¨æ­£åœ¨è¿è¡Œ
2. æ£€æŸ¥ URL å’Œç«¯å£æ˜¯å¦æ­£ç¡®
3. æ£€æŸ¥é˜²ç«å¢™è®¾ç½®

### é…ç½®å¤±è´¥

```json
{
  "type": "error",
  "error_code": "ENSEMBLE_NOT_FOUND"
}
```

**è§£å†³**:
1. ç¡®è®¤ Ensemble å·²åˆ›å»º
2. ä½¿ç”¨ `GET /api/v1/ensemble/list` æŸ¥çœ‹å¯ç”¨ Ensemble
3. æ£€æŸ¥æ‹¼å†™é”™è¯¯

### é¢„æµ‹å¤±è´¥

```json
{
  "type": "error",
  "error_code": "MISSING_SIGNALS"
}
```

**è§£å†³**:
1. æ£€æŸ¥æ‰€æœ‰å¿…éœ€çš„è¾¹ç•Œä¿¡å·æ˜¯å¦æä¾›
2. ä½¿ç”¨ `GET /api/v1/ensemble/{name}/info` æŸ¥çœ‹æ‰€éœ€ä¿¡å·
3. æ£€æŸ¥ä¿¡å·åç§°æ‹¼å†™

---

## ğŸ“š æ›´å¤šèµ„æº

- **å®Œæ•´ Demo**: `fastapi_inference/tests/demo_stream_client.py`
- **API æ–‡æ¡£**: http://localhost:8000/docs
- **ç»Ÿè®¡ä¿¡æ¯**: `GET /api/v1/inference/stream/stats`
- **ä¸»æ–‡æ¡£**: `fastapi_inference/README.md`

---

## ğŸ¯ æœ€ä½³å®è·µ

1. **è¿æ¥ç®¡ç†**
   - ä½¿ç”¨è¿æ¥æ± ç®¡ç†å¤šä¸ªè¿æ¥
   - å®ç°è‡ªåŠ¨é‡è¿æœºåˆ¶
   - å®šæœŸå‘é€ ping ä¿æŒè¿æ¥

2. **é”™è¯¯å¤„ç†**
   - æ•è·æ‰€æœ‰å¼‚å¸¸
   - å®ç°é‡è¯•é€»è¾‘
   - è®°å½•é”™è¯¯æ—¥å¿—

3. **æ€§èƒ½ä¼˜åŒ–**
   - æ ¹æ®åœºæ™¯é€‰æ‹©å•æ¡/æ‰¹é‡æ¨¡å¼
   - è°ƒæ•´æ‰¹é‡å¤§å°å¹³è¡¡å»¶è¿Ÿå’Œååé‡
   - ç›‘æ§å»¶è¿ŸæŒ‡æ ‡

4. **èµ„æºç®¡ç†**
   - åŠæ—¶å…³é—­ä¸ç”¨çš„è¿æ¥
   - å®šæœŸæ¸…ç†å†å²æ•°æ®
   - ç›‘æ§æœåŠ¡å™¨èµ„æºä½¿ç”¨

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¶é—´**: 2025-12-15
