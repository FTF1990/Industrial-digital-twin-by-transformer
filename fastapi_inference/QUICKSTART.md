# FastAPI Inference Service - Quick Start Guide

## ğŸš€ 3åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: ä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /path/to/Industrial-digital-twin-by-transformer
bash fastapi_inference/start_server.sh
```

### æ–¹å¼ 2: æ‰‹åŠ¨å¯åŠ¨

```bash
# 1. å®‰è£…ä¾èµ–
pip install -r fastapi_inference/requirements.txt

# 2. å¯åŠ¨æœåŠ¡
python -m fastapi_inference.main
```

### æ–¹å¼ 3: Colab ç¯å¢ƒ

```python
# åå°å¯åŠ¨
!cd /content/Industrial-digital-twin-by-transformer && \
  nohup python -m fastapi_inference.main > fastapi.log 2>&1 &

# ç­‰å¾…å¯åŠ¨
import time
time.sleep(5)

# æµ‹è¯•è¿æ¥
import requests
response = requests.get("http://localhost:8000/api/v1/health")
print(response.json())
```

## ğŸ“– è®¿é—®æ–‡æ¡£

å¯åŠ¨åè®¿é—®ï¼š

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## ğŸ§ª æµ‹è¯•è¿æ¥

```bash
# Bash
curl http://localhost:8000/api/v1/health

# Python
python fastapi_inference/tests/demo_api_client.py

# æˆ–è€…
bash fastapi_inference/tests/test_api.sh
```

## ğŸ“ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### 1. å‡†å¤‡æ•°æ®å’Œæ¨¡å‹

ç¡®ä¿ä½ æœ‰ï¼š
- âœ… Stage1 æ¨¡å‹çš„ `inference.json` é…ç½®æ–‡ä»¶
- âœ… Residual Boost æ¨¡å‹çš„ `inference.json` é…ç½®æ–‡ä»¶
- âœ… è¯„ä¼°æ•°æ® CSVï¼ˆåŒ…å«è¾¹ç•Œä¿¡å· + ç›®æ ‡ä¿¡å·çœŸå€¼ï¼‰
- âœ… æ¨ç†æ•°æ® CSVï¼ˆä»…éœ€è¾¹ç•Œä¿¡å·ï¼‰

### 2. ä½¿ç”¨ Python å®¢æˆ·ç«¯

```python
import requests

BASE_URL = "http://localhost:8000"

# 1. åŠ è½½ Stage1 æ¨¡å‹
response = requests.post(
    f"{BASE_URL}/api/v1/models/stage1/load",
    json={"inference_config_path": "saved_models/my_sst_model_inference.json"}
)
stage1_info = response.json()
print(f"Stage1 loaded: {stage1_info['model_name']}")

# 2. åŠ è½½ Residual Boost æ¨¡å‹
response = requests.post(
    f"{BASE_URL}/api/v1/models/residual-boost/load",
    json={"inference_config_path": "saved_models/tft_models/my_tft_inference.json"}
)
rb_info = response.json()
print(f"Residual Boost loaded: {rb_info['model_name']}")

# 3. åˆ›å»º Ensemble
response = requests.post(
    f"{BASE_URL}/api/v1/ensemble/create",
    json={
        "stage1_model_name": stage1_info['model_name'],
        "residual_boost_model_name": rb_info['model_name'],
        "evaluation_data_path": "data/evaluation_data.csv",
        "delta_r2_threshold": 0.05
    }
)
ensemble_info = response.json()
ensemble_name = ensemble_info['ensemble_name']
print(f"Ensemble created: {ensemble_name}")

# 4. æ‰¹é‡æ¨ç†
response = requests.post(
    f"{BASE_URL}/api/v1/inference/batch",
    json={
        "ensemble_name": ensemble_name,
        "input_data_path": "data/new_data.csv",
        "output_dir": "fastapi_inference/results"
    }
)
result = response.json()
print(f"Predictions saved to: {result['output_path']}")
```

### 3. ä½¿ç”¨ curl

```bash
# 1. åŠ è½½æ¨¡å‹
curl -X POST "http://localhost:8000/api/v1/models/stage1/load" \
  -H "Content-Type: application/json" \
  -d '{"inference_config_path": "saved_models/my_sst_model_inference.json"}'

# 2. åˆ›å»º Ensemble
curl -X POST "http://localhost:8000/api/v1/ensemble/create" \
  -H "Content-Type: application/json" \
  -d '{
    "stage1_model_name": "my_sst_model",
    "residual_boost_model_name": "my_tft_model",
    "evaluation_data_path": "data/evaluation_data.csv",
    "delta_r2_threshold": 0.05
  }'

# 3. æ¨ç†
curl -X POST "http://localhost:8000/api/v1/inference/batch" \
  -H "Content-Type: application/json" \
  -d '{
    "ensemble_name": "Ensemble_my_sst_model_20251215_103000",
    "input_data_path": "data/new_data.csv",
    "output_dir": "fastapi_inference/results"
  }'
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶

æ¨ç†ç»“æœä¿å­˜åœ¨ `output_dir` æŒ‡å®šçš„ç›®å½•ï¼š

- `predictions_{ensemble_name}_{timestamp}.csv` - é¢„æµ‹ç»“æœ
- `predictions_{ensemble_name}_{timestamp}_metadata.txt` - å…ƒæ•°æ®ä¿¡æ¯

## ğŸ” æŸ¥çœ‹æ—¥å¿—

```bash
# å¦‚æœä½¿ç”¨å¯åŠ¨è„šæœ¬ï¼Œæ—¥å¿—åœ¨ç»ˆç«¯æ˜¾ç¤º
# å¦‚æœåå°è¿è¡Œï¼ŒæŸ¥çœ‹æ—¥å¿—æ–‡ä»¶
tail -f fastapi.log
```

## â“ å¸¸è§é—®é¢˜

### Q: ç«¯å£è¢«å ç”¨æ€ä¹ˆåŠï¼Ÿ

ä¿®æ”¹ `fastapi_inference/config.py` ä¸­çš„ `PORT` é…ç½®ã€‚

### Q: GPU æ²¡æœ‰è¢«ä½¿ç”¨ï¼Ÿ

æ£€æŸ¥ PyTorch CUDA æ˜¯å¦å®‰è£…æ­£ç¡®ï¼š
```python
import torch
print(torch.cuda.is_available())
```

### Q: æ¨¡å‹æ–‡ä»¶æ‰¾ä¸åˆ°ï¼Ÿ

ç¡®ä¿è·¯å¾„ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼Œæˆ–ä½¿ç”¨ç»å¯¹è·¯å¾„ã€‚

## ğŸ“š æ›´å¤šæ–‡æ¡£

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒï¼š`fastapi_inference/README.md`
